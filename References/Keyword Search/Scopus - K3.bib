
@ARTICLE{Barzamini2022161,
author={Barzamini, H. and Shahzad, M. and Alhoori, H. and Rahimi, M.},
title={A multi-level semantic web for hard-to-specify domain concept, Pedestrian, in ML-based software},
journal={Requirements Engineering},
year={2022},
volume={27},
number={2},
pages={161-182},
doi={10.1007/s00766-021-00366-0},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122679533&doi=10.1007%2fs00766-021-00366-0&partnerID=40&md5=b3dcf792c3adcc0313a4c97dfff3c9ae},
abstract={Machine Learning (ML) algorithms are widely used in building software-intensive systems, including safety-critical ones. Unlike traditional software components, Machine-Learned Components (MLC)s, software components built using ML algorithms, learn their specifications through generalizing the common features that they find in a limited set of collected examples. While this inductive nature overcomes the limitations of programming hard-to-specify concepts, the same feature becomes problematic for verifying safety in ML-based software systems. One reason is that, due to MLCs data-driven nature, there is often no set of explicitly written and pre-defined specifications, against which the MLC can be verified. In this regard, we propose to partially specify hard-to-specify domain concepts, which MLCs tend to classify, instead of fully relying on their inductive learning ability from arbitrarily-collected datasets. In this paper, we propose a semi-automated approach to construct a multi-level semantic web to partially outline the hard-to-specify, yet crucial, domain concept “pedestrian” in automotive domain. We evaluate the applicability of the generated semantic web in two ways: first, with a reference to the web, we augment a pedestrian dataset for a missing feature, wheelchair, to show training a state-of-the-art ML-based object detector on the augmented dataset improves its accuracy in detecting pedestrians; second, we evaluate the coverage of the generated semantic web based on multiple state-of-the-art pedestrian and human datasets. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.},
author_keywords={Machine learning;  Machine-learned components;  Requirements specifications;  Safety-critical systems},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={09473602},
language={English},
document_type={Article},
source={Scopus},
}

@ARTICLE{Siddharth2022,
author={Siddharth, L. and Blessing, L.T.M. and Wood, K.L. and Luo, J.},
title={Engineering Knowledge Graph From Patent Database},
journal={Journal of Computing and Information Science in Engineering},
year={2022},
volume={22},
number={2},
doi={10.1115/1.4052293},
art_number={021008},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127396038&doi=10.1115%2f1.4052293&partnerID=40&md5=de3757d92d71347d71f951268042e933},
abstract={We propose a large, scalable engineering knowledge graph, comprising sets of real-world engineering “facts” as < entity, relationship, entity > triples that are found in the patent database. We apply a set of rules based on the syntactic and lexical properties of claims in a patent document to extract facts. We aggregate these facts within each patent document and integrate the aggregated sets of facts across the patent database to obtain an engineering knowledge graph. Such a knowledge graph is expected to support inference, reasoning, and recalling in various engineering tasks. The knowledge graph has a greater size and coverage in comparison with the previously used knowledge graphs and semantic networks in the engineering literature. Copyright © 2021 by ASME.},
author_keywords={Information management;  Knowledge engineering},
publisher={American Society of Mechanical Engineers (ASME)},
issn={15309827},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Chiatti2022,
author={Chiatti, A. and Motta, E. and Daga, E.},
title={Robots With Commonsense: Improving Object Recognition Through Size and Spatial Awareness},
journal={CEUR Workshop Proceedings},
year={2022},
volume={3121},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128785525&partnerID=40&md5=aad5d89a246b47c23c92d1bad5e36f53},
abstract={To effectively assist us with our daily tasks, service robots need object recognition methods that perform robustly in dynamic environments. Our prior work has shown that augmenting Deep Learning (DL) methods with knowledge-based reasoning can drastically improve the reliability of object recognition systems. This paper proposes a novel method to equip DL-based object recognition with the ability to reason on the typical size and spatial relations of objects. Experiments in a real-world robotic scenario show that the proposed hybrid architecture significantly outperforms DL-only solutions. © 2022 Copyright for this paper by its authors},
author_keywords={commonsense reasoning;  hybrid intelligence;  service robotics;  visual intelligence},
publisher={CEUR-WS},
issn={16130073},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Althar2021186,
author={Althar, R.R. and Samanta, D.},
title={Application of machine intelligence-based knowledge graphs for software engineering},
journal={Methodologies and Applications of Computational Statistics for Machine Intelligence},
year={2021},
pages={186-202},
doi={10.4018/978-1-7998-7701-1.ch010},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124792951&doi=10.4018%2f978-1-7998-7701-1.ch010&partnerID=40&md5=6d06593a7697903a3c01240f9ceaa7df},
abstract={This chapter focuses on knowledge graphs application in software engineering. It starts with a general exploration of artificial intelligence for software engineering and then funnels down to the area where knowledge graphs can be a good fit. The focus is to put together work done in this area and call out key learning and future aspirations. The knowledge management system's architecture, specific application of the knowledge graph in software engineering like automation of test case creation and aspiring to build a continuous learning system are explored. Understanding the semantics of the knowledge, developing an intelligent development environment, defect prediction with network analysis, and clustering of the graph data are exciting explorations. © 2021, IGI Global.},
publisher={IGI Global},
isbn={9781799877035; 9781799877011},
language={English},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Wen20211042,
author={Wen, Z. and Peng, Y.},
title={Multi-Level Knowledge Injecting for Visual Commonsense Reasoning},
journal={IEEE Transactions on Circuits and Systems for Video Technology},
year={2021},
volume={31},
number={3},
pages={1042-1054},
doi={10.1109/TCSVT.2020.2991866},
art_number={9083951},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102236279&doi=10.1109%2fTCSVT.2020.2991866&partnerID=40&md5=68b30f52154438581ac4ba96e4fad483},
abstract={When glancing at an image, human can infer what is hidden in the image beyond what is visually obvious, such as objects' functions, people's intents and mental states. However, such a visual reasoning paradigm is tremendously difficult for computer, requiring knowledge about how the world works. To address this issue, we propose Commonsense Knowledge based Reasoning Model (CKRM) to acquire external knowledge to support Visual Commonsense Reasoning (VCR) task, where the computer is expected to answer challenging visual questions. Our key ideas are: (1) To bridge the gap between recognition-level and cognition-level image understanding, we inject external commonsense knowledge via multi-level knowledge transfer network, achieving cell-level, layer-level and attention-level joint information transfer. It can effectively capture knowledge from different perspectives, and perceive common sense of human in advance. (2) To further promote image understanding at cognitive level, we propose a knowledge based reasoning approach, which can relate the transferred knowledge to visual content and compose the reasoning cues to derive the final answer. Experiments are conducted on the challenging visual commonsense reasoning dataset VCR to verify the effectiveness of our proposed CKRM approach, which can significantly improve reasoning performance and achieve the state-of-The-Art accuracy. © 1991-2012 IEEE.},
author_keywords={knowledge representation;  transfer learning;  Visual commonsense reasoning;  visual question answering},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={10518215},
coden={ITCTE},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Janik20212638,
author={Janik, M. and Gard, N. and Hilsmann, A. and Eisert, P.},
title={ZERO IN ON SHAPE: A GENERIC 2D-3D INSTANCE SIMILARITY METRIC LEARNED FROM SYNTHETIC DATA},
journal={Proceedings - International Conference on Image Processing, ICIP},
year={2021},
volume={2021-September},
pages={2638-2642},
doi={10.1109/ICIP42928.2021.9506436},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125566041&doi=10.1109%2fICIP42928.2021.9506436&partnerID=40&md5=821d05f9b554003dcbbf952f0d9ad091},
abstract={We present a network architecture which compares RGB images and untextured 3D models by the similarity of the represented shape. Our system is optimised for zero-shot retrieval, meaning it can recognise shapes never shown in training. We use a view-based shape descriptor and a siamese network to learn object geometry from pairs of 3D models and 2D images. Due to scarcity of datasets with exact photograph-mesh correspondences, we train our network with only synthetic data. Our experiments investigate the effect of different qualities and quantities of training data on retrieval accuracy and present insights from bridging the domain gap. We show that increasing the variety of synthetic data improves retrieval accuracy and that our system’s performance in zero-shot mode can match that of the instance-aware mode, as far as narrowing down the search to the top 10% of objects. © 2021 IEEE},
author_keywords={3D model retrieval;  Domain gap;  Siamese networks;  Synthetic data;  Zero-shot},
publisher={IEEE Computer Society},
issn={15224880},
isbn={9781665441155},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Silenzi2021189,
author={Silenzi, M.I.},
title={About the original frame problem and some other related problems [Acerca del problema de marco original y algunos otros problemas relacionados]},
journal={Topicos},
year={2021},
number={42},
pages={189-215},
doi={10.14409/TOPICOS.V0I42.8795},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123090121&doi=10.14409%2fTOPICOS.V0I42.8795&partnerID=40&md5=222d5da6cc581494aa0e170b46311435},
abstract={The frame problem is one of the most controversial and difficult problems to solve within the field of philosophy of the mind, and even today it has not been possible to reach a consensus on its definition or its solution. It is for this reason that our main objective is to clarify the original frame problem, and some other related problems. We will argue that even this formulation of the problem, among several, has many aspects and that it cannot be understood as “one” problem only but rather as a set of problems closely related to the same issue. © 2021 Asociacion Revista de Filosofia de Santa Fe. All rights reserved.},
author_keywords={Frame problem;  Logic interpretation;  Logic resolutions;  Related problems},
publisher={Asociacion Revista de Filosofia de Santa Fe},
issn={1666485X},
language={Spanish},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Sarica20211043,
author={Sarica, S. and Luo, J.},
title={Design knowledge representation with technology semantic network},
journal={Proceedings of the Design Society},
year={2021},
volume={1},
pages={1043-1052},
doi={10.1017/pds.2021.104},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117789537&doi=10.1017%2fpds.2021.104&partnerID=40&md5=cd633fb775d4dfb47840cdfc998e44ab},
abstract={Engineers often need to discover and learn designs from unfamiliar domains for inspiration or other particular uses. However, the complexity of the technical design descriptions and the unfamiliarity to the domain make it hard for engineers to comprehend the function, behavior, and structure of a design. To help engineers quickly understand a complex technical design description new to them, one approach is to represent it as a network graph of the design-related entities and their relations as an abstract summary of the design. While graph or network visualizations are widely adopted in the engineering design literature, the challenge remains in retrieving the design entities and deriving their relations. In this paper, we propose a network mapping method that is powered by Technology Semantic Network (TechNet). Through a case study, we showcase how TechNet's unique characteristic of being trained on a large technology-related data source advantages itself over common-sense knowledge bases, such as WordNet and ConceptNet, for design knowledge representation. © ICED 2021.All right reserved.},
author_keywords={Design informatics;  Knowledge Representation;  Semantic data processing;  Technology Semantic Network;  Visualisation},
publisher={Cambridge University Press},
issn={2732527X},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Nabizadeh2021341,
author={Nabizadeh, N. and Wersing, H. and Kolossa, D.},
title={Leveraging Inter-step Dependencies for Information Extraction from Procedural Task Instructions},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2021},
volume={12848 LNAI},
pages={341-353},
doi={10.1007/978-3-030-83527-9_29},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115228256&doi=10.1007%2f978-3-030-83527-9_29&partnerID=40&md5=73b10957c1b3b86218089256fec616ec},
abstract={Written instructions are among the most prevalent means of transferring procedural knowledge. Hence, enabling computers to obtain information from textual instructions is crucial for future AI agents. Extracting information from a step of a multi-part instruction is usually performed by solely considering the semantic and syntactic information of the step itself. In procedural task instructions, however, there is a sequential dependency across entities throughout the entire task, which would be of value for optimal information extraction. However, conventional language models such as transformers have difficulties processing long text, i.e., the entire instruction text from the first step to the last one, since their scope of attention is limited to a relatively short chunk of text. As a result, the dependencies among the steps of a longer procedure are often overlooked. This paper suggests a BERT-GRU model for leveraging sequential dependencies among all steps in a procedure. We present experiments on annotated datasets of text instructions in two different domains, i.e., repairing electronics and cooking, showing our model’s advantage compared to standard transformer models. Moreover, we employ a sequence prediction model to show the correlation between the predictability of tags and the performance benefit achieved by leveraging inter-step dependencies. © 2021, Springer Nature Switzerland AG.},
author_keywords={Information extraction;  Instructional text;  Long-term dependencies;  Procedural task},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={03029743},
isbn={9783030835262},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Wang202153,
author={Wang, Y. and Cao, C. and Cao, Y. and Wang, S.},
title={A Property-Based Method for Acquiring Commonsense Knowledge},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2021},
volume={12815 LNAI},
pages={53-65},
doi={10.1007/978-3-030-82136-4_5},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113816921&doi=10.1007%2f978-3-030-82136-4_5&partnerID=40&md5=a813de46d16c5ed88e0a378921e72ec0},
abstract={Commonsense knowledge is crucial in a variety of AI applications. However, one kind of commonsense knowledge that has not received attention is that of properties of actions denoted by verbs. To address this limitation, we propose an approach to acquiring commonsense knowledge about action properties. In this paper, we take self-motion actions as an example to present our method. We first identify commonsense properties of actions from their definitions. We then introduce a list of dimensions for acquiring commonsense knowledge based on adjectives. Finally, we extract commonsense knowledge from text by parsing sentences that involve actions. Experiments show that our method allows to obtain high-quality commonsense knowledge. © 2021, Springer Nature Switzerland AG.},
author_keywords={Action properties;  Commonsense knowledge;  Dimensions;  Text parsing},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={03029743},
isbn={9783030821357},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Losing202181,
author={Losing, V. and Fischer, L. and Deigmoeller, J.},
title={Extraction of common-sense relations from procedural task instructions using BERT},
journal={GWC 2021 - Proceedings of the 11th Global Wordnet Conference},
year={2021},
pages={81-90},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109510229&partnerID=40&md5=d7a6bf1cb02d65a23eb5472428117a71},
abstract={Manipulation-relevant common-sense knowledge is crucial to support action-planning for complex tasks. In particular, instrumentality information of what can be done with certain tools can be used to limit the search space which is growing exponentially with the number of viable options. Typical sources for such knowledge, structured common-sense knowledge bases such as ConceptNet or WebChild, provide a limited amount of information which also varies drastically across different domains. Considering the recent success of pre-trained language models such as BERT, we investigate whether common-sense information can directly be extracted from semi-structured text with an acceptable annotation effort. Concretely, we compare the common-sense relations obtained from ConceptNet versus those extracted with BERT from large recipe databases. In this context, we propose a scoring function, based on the WordNet taxonomy to match specific terms to more general ones, enabling a rich evaluation against a set of ground-truth relations. © GWC 2021. All rights reserved.},
publisher={Global WordNet Association},
isbn={9789464027310},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Toschev2020811,
author={Toschev, A. and Talanov, M.},
title={Artificial Cognitive Architectures Review},
journal={BioNanoScience},
year={2020},
volume={10},
number={4},
pages={811-823},
doi={10.1007/s12668-020-00768-4},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088293255&doi=10.1007%2fs12668-020-00768-4&partnerID=40&md5=3f0d481d55a73edfaa5ce7ad071640fc},
abstract={In this work we present the review of cognitive architectures and bio-inspired approaches used for cognitive modeling with focus on consciousness and common sense computational implementation. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.},
author_keywords={Cognitive modeling;  Common sense;  Consciousness;  Models},
publisher={Springer},
issn={21911630},
language={English},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Zhang202036,
author={Zhang, S. and Li, X. and Liu, Y. and Fu, H.},
title={Scale-aware Insertion of Virtual Objects in Monocular Videos},
journal={Proceedings - 2020 IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2020},
year={2020},
pages={36-44},
doi={10.1109/ISMAR50242.2020.00022},
art_number={9284812},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099280567&doi=10.1109%2fISMAR50242.2020.00022&partnerID=40&md5=896f63015b24e16f27196bae1fa4f746},
abstract={In this paper, we propose a scale-aware method for inserting virtual objects with proper sizes into monocular videos. To tackle the scale ambiguity problem of geometry recovery from monocular videos, we estimate the global scale objects in a video with a Bayesian approach incorporating the size priors of objects, where the scene objects sizes should strictly conform to the same global scale and the possibilities of global scales are maximized according to the size distribution of object categories. To do so, we propose a dataset of sizes of object categories: Metric-Tree, a hierarchical representation of sizes of more than 900 object categories with the corresponding images. To handle the incompleteness of objects recovered from videos, we propose a novel scale estimation method that extracts plausible dimensions of objects for scale optimization. Experiments have shown that our method for scale estimation performs better than the state-of-the-art methods, and has considerable validity and robustness for different video scenes. Metric-Tree has been made available at: https://metric-tree.github.io © 2020 IEEE.},
author_keywords={Computer graphics;  Computing methodologies;  Graphics systems and interfaces},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728185088},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Wang2020,
author={Wang, Z. and Tian, G. and Shao, X.},
title={Home service robot task planning using semantic knowledge and probabilistic inference},
journal={Knowledge-Based Systems},
year={2020},
volume={204},
doi={10.1016/j.knosys.2020.106174},
art_number={106174},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087338617&doi=10.1016%2fj.knosys.2020.106174&partnerID=40&md5=6ae1b1c771aec6e3570bc2922baed66f},
abstract={In the face of unstructured home environment, home service robots are inevitably confronted with uncertainty and incompleteness of environment information. How to make the home service robot obtain enough environment information and plan a discrete sequence of actions through task planning is the key problem of robot intelligence. In this paper, a hierarchical task network based on semantic knowledge and probabilistic inference method is proposed. We use the object location ontology, the location relation between dynamic and static objects to build semantic knowledge of home environment, and build the probability model between dynamic and static objects, as well as between static objects and home scenes. The location of the object is determined by the semantic knowledge and the probability model. Hierarchical task network is selected as an engine of task planner, which can be provided with the location information to improve the autonomy and effectiveness of robot task planning. In order to prevent task execution failure and enhance the adaptability of robot to unstructured home environment, a mechanism of task execution diagnosis and replanning is designed. Experimental results in simulation and real home environment demonstrate that our method can effectively improve the performance of service robot task planning and generate better task execution sequence. © 2020 Elsevier B.V.},
author_keywords={Hierarchical task network;  Home environment;  Probabilistic inference;  Semantic knowledge;  Task execution diagnosis;  Task planning},
publisher={Elsevier B.V.},
issn={09507051},
coden={KNSYE},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Lu2020332,
author={Lu, P. and Qin, Z. and Liao, Y.},
title={A Novel Formal Representation and Reasoning for Commonsense Knowledge},
journal={Proceedings - 2020 4th Annual International Conference on Data Science and Business Analytics, ICDSBA 2020},
year={2020},
pages={332-335},
doi={10.1109/ICDSBA51020.2020.00092},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116668734&doi=10.1109%2fICDSBA51020.2020.00092&partnerID=40&md5=392dd081d403c2d93683eb14c0cd0882},
abstract={Commonsense knowledge reasoning is an important an important research field in artificial intelligence, and there has been a lot of research. But there is still much work to be done on the basic theory of commonsense knowledge formalization. In this article, we introduce a novel quantifier in first- order logic, called "collective quantifier", in order to construct a logical framework for the formal representation and reasoning of commonsense knowledge. After giving the semantic explanation of the collective quantifier, the complete formal expression of commonsense knowledge is realized. The proposed quantifier is slightly weaker than the universal quantifier. The universal quantifier describes the "characteristics of all individuals in the universe", while the collective quantifier describes the "characteristics of most individuals in the universe". In addition, we also propose a multi-level commonsense knowledge representation and reasoning, which divides the attribute values of commonsense knowledge into multiple levels for processing. For example, the commonsense knowledge "rainfall can cause floods"is divided into "heavy rains can cause catastrophic floods"or "heavy rains can cause major floods". Multi-level commonsense knowledge reasoning broadens the application scope of Classical commonsense knowledge reasoning. © 2020 IEEE.},
author_keywords={Collective Quantifier;  Commonsense Knowledge Reasoning;  Multi-level Attributes;  Reliability Factor;  Semantic Interpretation},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728181646},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kim2020324,
author={Kim, M. and Kim, J. and Park, G. and Seo, J.},
title={PolySquare},
journal={International Conference on Intelligent User Interfaces, Proceedings IUI},
year={2020},
pages={324-334},
doi={10.1145/3377325.3377484},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082471794&doi=10.1145%2f3377325.3377484&partnerID=40&md5=9726038cedce283cc8c62d021bccaf7d},
abstract={Searching for desired 3D models is not easy because many of them are not well labeled; annotations often contain inconsistent information (e.g., uploaders' personal way of naming) and lack important details (e.g., detailed ornaments and pattern) of each model. We introduce PolySquare, a search engine for 3D models based on tag propagation - -the process of assigning existing tags to other similar but unlabeled models considering important local properties. For instance, a tag 'wheel' of a wheelchair can be spread out to other objects with wheels. Furthermore, PolySquare allows people to interactively refine the search results by iteratively including desired shapes and excluding unwanted ones. We evaluate the performance of tag propagation by measuring the precision-recall of propagation results with various similarity thresholds and demonstrate the effectiveness of the use of local features. We also showcase how PolySquare handles the unrefined tags through a case study using real 3D model data from Google Poly. © ACM.},
author_keywords={3D data retrieval;  3D model search;  3D tagging;  3D text annotation;  neural networks},
publisher={Association for Computing Machinery},
isbn={9781450371186},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Nabizadeh2020156,
author={Nabizadeh, N. and Heckmann, M. and Kolossa, D.},
title={Target-Aware Prediction of Tool Usage in Sequential Repair Tasks},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12566 LNCS},
pages={156-168},
doi={10.1007/978-3-030-64580-9_13},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101351741&doi=10.1007%2f978-3-030-64580-9_13&partnerID=40&md5=ec0acdefa9095f96cd09319c79ebc691},
abstract={Repairing a device is usually a sequential task comprising several steps, each potentially involving a different tool. Learning the sequential pattern of tool usage would be helpful for various assistance scenarios, e.g. allowing a contextualized assistant to predict the next required tool in an unseen task. In this work, we examine the potential of this idea. We employ two prominent classes of sequence learning methods for modeling the tool usage, including Variable Order Markov Models (VMMs) and Recurrent Neural Networks (RNNs). We then extend these methods by also conditioning them on additional information from the repair manuals that represents the repair target. This information is present, for example, in the title of manuals. We investigate the effect of long-term dependencies and of target-awareness on the prediction performance and compare the methods in terms of accuracy and training time. The evaluation using an annotated dataset of repair manuals shows that both target-awareness and long-term dependencies have a substantial effect on the tool prediction. While the RNN has slightly more accurate predictions in most scenarios, the VMM has a lower training time and is beneficial when the prediction needs to be restricted with respect to the device category. © 2020, Springer Nature Switzerland AG.},
author_keywords={Recurrent Neural Network;  Repair tasks;  Sequence learning;  Target-awareness;  Variable Order Markov Model},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={03029743},
isbn={9783030645793},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Nabizadeh20202120,
author={Nabizadeh, N. and Kolossa, D. and Heckmann, M.},
title={MyFixit: An annotated dataset, annotation tool, and baseline methods for information extraction from repair manuals},
journal={LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings},
year={2020},
pages={2120-2128},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096530664&partnerID=40&md5=bcb20c45b413490f2ac80809e5ef893d},
abstract={Text instructions are among the most widely used media for learning and teaching. Hence, to create assistance systems that are capable of supporting humans autonomously in new tasks, it would be immensely productive, if machines were enabled to extract task knowledge from such text instructions. In this paper, we, therefore, focus on information extraction (IE) from the instructional text in repair manuals. This brings with it the multiple challenges of information extraction from the situated and technical language in relatively long and often complex instructions. To tackle these challenges, we introduce a semi-structured dataset of repair manuals. The dataset is annotated in a large category of devices, with information that we consider most valuable for an automated repair assistant, including the required tools and the disassembled parts at each step of the repair progress. We then propose methods that can serve as baselines for this IE task: an unsupervised method based on a bags-of-n-grams similarity for extracting the needed tools in each repair step, and a deep-learning-based sequence labeling model for extracting the identity of disassembled parts. These baseline methods are integrated into a semi-automatic web-based annotator application that is also available along with the dataset. © European Language Resources Association (ELRA), licensed under CC-BY-NC},
author_keywords={Information extraction;  Instructional text;  Procedural task;  Repair manual;  Semi-automatic annotation web tool;  Semi-structured dataset},
publisher={European Language Resources Association (ELRA)},
isbn={9791095546344},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Janai20201,
author={Janai, J. and Güney, F. and Behl, A. and Geiger, A.},
title={Computer vision for autonomous vehicles},
journal={Foundations and Trends in Computer Graphics and Vision},
year={2020},
volume={12},
number={1-3},
pages={1-308},
doi={10.1561/0600000079},
note={cited By 93},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091790753&doi=10.1561%2f0600000079&partnerID=40&md5=6e3a4f5ae2b596520adc9378b3167f65},
abstract={Recent years have witnessed enormous progress in AI-related fields such as computer vision, machine learning, and autonomous vehicles. As with any rapidly growing field, it becomes increasingly difficult to stay up-to-date or enter the field as a beginner. While several survey papers on particular sub-problems have appeared, no comprehensive survey on problems, datasets, and methods in computer vision for autonomous vehicles has been published. This monograph attempts to narrow this gap by providing a survey on the state-of-the-art datasets and techniques. Our survey includes both the historically most relevant literature as well as the current state of the art on several specific topics, including recognition, reconstruction, motion estimation, tracking, scene understanding, and end-to-end learning for autonomous driving. Towards this goal, we analyze the performance of the state of the art on several challenging benchmarking datasets, including KITTI, MOT, and Cityscapes. Besides, we discuss open problems and current research challenges. To ease accessibility and accommodate missing references, we also provide a website that allows navigating topics as well as methods and provides additional information. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.},
publisher={Now Publishers Inc},
issn={15722740},
language={English},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gezawa202057566,
author={Gezawa, A.S. and Zhang, Y. and Wang, Q. and Yunqi, L.},
title={A review on deep learning approaches for 3d data representations in retrieval and classifications},
journal={IEEE Access},
year={2020},
volume={8},
pages={57566-57593},
doi={10.1109/ACCESS.2020.2982196},
art_number={9043500},
note={cited By 17},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082810512&doi=10.1109%2fACCESS.2020.2982196&partnerID=40&md5=d2a149dc4c5206eee3cce59825de4c42},
abstract={Deep learning approach has been used extensively in image analysis tasks. However, implementing the methods in 3D data is a bit complex because most of the previously designed deep learning architectures used 1D or 2D as input. In this work, the performance of deep learning methods on different 3D data representations has been reviewed. Based on the categorization of the different 3D data representations proposed in this paper, the importance of choosing a suitable 3D data representation which depends on simplicity, usability, and efficiency has been highlighted. Furthermore, the origin and contents of the major 3D datasets were discussed in detail. Due to growing interest in 3D object retrieval and classification tasks, the performance of different 3D object retrieval and classification on ModelNet40 dataset were compared. According to the findings in this work, multi views methods surpass voxel-based methods and with increased layers and enough data augmentation the performance can still be increased. Therefore, it can be concluded that deep learning together with a suitable 3D data representation gives an effective approach for improving the performance of 3D shape analysis. Finally, some possible directions for future researches were suggested. © 2013 IEEE.},
author_keywords={3D data representation;  3D deep learning;  3D models dataset;  Classification;  Computer vision;  Retrieval},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={21693536},
language={English},
document_type={Review},
source={Scopus},
}

@ARTICLE{Cunningham2019,
author={Cunningham, J.D. and Simpson, T.W. and Tucker, C.S.},
title={An investigation of surrogate models for efficient performance-based decoding of 3d point clouds},
journal={Journal of Mechanical Design, Transactions of the ASME},
year={2019},
volume={141},
number={12},
doi={10.1115/1.4044597},
art_number={121401},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085116060&doi=10.1115%2f1.4044597&partnerID=40&md5=e322d67fa581302e5c038632cb374bce},
abstract={This work investigates surrogate modeling techniques for learning to approximate a computationally expensive function evaluation of 3D models. While in the past, 3D point clouds have been a data format that is too high dimensional for surrogate modeling, by leveraging advances in 3D object autoencoding neural networks, these point clouds can be mapped to a one-dimensional latent space. This leads to the fundamental research question: what surrogate modeling technique is most suitable for learning relationships between the 3D geometric features of the objects captured in the encoded latent vector and the physical phenomena captured in the evaluation software? Radial basis functions (RBFs), Kriging, and shallow 1D analogs of popular deep 2D image classification neural networks are investigated in this work. We find the nonintuitive result that departing from neural networks to decode latent representations of 3D objects into performance predictions is far more efficient than using a neural network decoder. In test cases using datasets of aircraft and watercraft 3D models, the non-neural network surrogate models achieve comparable accuracy to the neural network models. We find that an RBF surrogate model is able to approximate the lift and drag coefficients of 234 aircraft models with a mean absolute error of 1.97 × 10−3 and trains in only 3 seconds. Furthermore, the RBF surrogate model is able to rank a set of designs with an average percentile error of less than 8%. In comparison, a 1D ResNet achieves an average absolute error of 1.35 × 103 in 38 min for the same test case. We validate the comparable accuracy of the four techniques through a test case involving 214 3D watercraft models, but we also find that the distribution of the performance values of the data, in particular the presence of many outliers, has a significant negative impact on accuracy. These results contradict a common perception of neural networks as an efficient “one-size-fits-all” solution for learning black-box functions and suggests that even within systems that utilize multiple neural networks, potentially more efficient alternatives should be considered for each network in the system. Depending on the required accuracy of the application, this surrogate modeling approach could be used to approximate an expensive simulation software, or if the tolerance for error is low, it serves as a first pass which can narrow down the number of candidate designs to be analyzed more thoroughly. Copyright © 2019 by ASME},
author_keywords={Computer-aided design;  Conceptual design;  Design automation;  Generative design;  Metamodeling},
publisher={American Society of Mechanical Engineers (ASME)},
issn={10500472},
coden={JMDEE},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Samb2019112,
author={Samb, S.M.K. and Kande, D. and Camara, F. and Ndiaye, S.},
title={Improved Bilingual Sentiment Analysis Lexicon Using Word-level Trigram},
journal={2019 IEEE 5th International Conference on Computer and Communications, ICCC 2019},
year={2019},
pages={112-119},
doi={10.1109/ICCC47050.2019.9064223},
art_number={9064223},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084070276&doi=10.1109%2fICCC47050.2019.9064223&partnerID=40&md5=a06d31b4730f163cee1f59d2f8a36902},
abstract={In social networks, Senegalese citizen freely express their opinions using French and Wolof Languages, which often leads to a lot of spelling mistakes in their writing. Furthermore, the complexity of Wolof language in orthography and French language in grammar and conjugation makes the analysis of Senegalese citizen's opinions more challenging. FWLSA-score [1], has been recently proposed as an effective solution for overcoming the complexities of this bilingual sentiment analysis. This solution was based on word-level similarity. But, it does not deal perfectly with verbs' conjugation or some words' declination in both languages. This paper proposes an improvement of FWLSA-score [1] to address these issues. The new contribution is based on the word-level trigrams (list of consecutive three letters). Experimental results conducted on the same data [2], show that it successfully predicts sentiment polarity with an accuracy of 96.83% (implying an increase of 5.93% compared to the previous work). © 2019 IEEE.},
author_keywords={naturel language processing;  opinion mining;  sentiment analysis},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728147437},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Sutherland2019,
author={Sutherland, A. and Magg, S. and Wermter, S.},
title={Leveraging Recursive Processing for Neural-Symbolic Affect-Target Associations},
journal={Proceedings of the International Joint Conference on Neural Networks},
year={2019},
volume={2019-July},
doi={10.1109/IJCNN.2019.8851875},
art_number={8851875},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073214635&doi=10.1109%2fIJCNN.2019.8851875&partnerID=40&md5=b82a0033c14dffff1f50b3734a3eacb4},
abstract={Explaining the outcome of deep learning decisions based on affect is challenging but necessary if we expect social companion robots to interact with users on an emotional level. In this paper, we present a commonsense approach that utilizes an interpretable hybrid neural-symbolic system to associate extracted targets, noun chunks determined to be associated with the expressed emotion, with affective labels from a natural language expression. We leverage a pre-trained neural network that is well adapted to tree and sub-tree processing, the Dependency Tree-LSTM, to learn the affect labels of dynamic targets, determined through symbolic rules, in natural language. We find that making use of the unique properties of the recursive network provides higher accuracy and interpretability when compared to other unstructured and sequential methods for determining target-affect associations in an aspect-based sentiment analysis task. © 2019 IEEE.},
author_keywords={affective computing;  hybrid;  natural language processing;  neural-symbolic;  recursive;  sentiment},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728119854},
coden={85OFA},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Haidu20192606,
author={Haidu, A. and Beetz, M.},
title={Automated models of human everyday activity based on game and virtual reality technology},
journal={Proceedings - IEEE International Conference on Robotics and Automation},
year={2019},
volume={2019-May},
pages={2606-2612},
doi={10.1109/ICRA.2019.8793859},
art_number={8793859},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071498098&doi=10.1109%2fICRA.2019.8793859&partnerID=40&md5=7b37fe38383c8f6c5e79154f809b88f0},
abstract={In this paper, we will describe AMEvA (Automated Models of Everyday Activities), a special-purpose knowledge acquisition, interpretation, and processing system for human everyday manipulation activity that can automatically: (1) create and simulate virtual human living and working environments (such as kitchens and apartments) with a scope, extent, level of detail, physics, and close to photorealism that facilitates and promotes the natural and realistic execution of human everyday manipulation activities; (2) record human manipulation activities performed in the respective virtual reality environment as well as their effects on the environment and detect force-dynamic states and events; (3) decompose and segment the recorded activity data into meaningful motions and categorize the motions according to action models used in cognitive science; and (4) represent the interpreted activities symbolically in KNOWROB [1] using a first-order time interval logic representation. © 2019 IEEE.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={10504729},
isbn={9781538660263},
coden={PIIAE},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Rostami2019356,
author={Rostami, R. and Bashiri, F.S. and Rostami, B. and Yu, Z.},
title={A Survey on Data-Driven 3D Shape Descriptors},
journal={Computer Graphics Forum},
year={2019},
volume={38},
number={1},
pages={356-393},
doi={10.1111/cgf.13536},
note={cited By 20},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052811189&doi=10.1111%2fcgf.13536&partnerID=40&md5=270c32719c6b55a4998f8e09337bb50c},
abstract={Recent advances in scanning device technologies and improvements in techniques that generate and synthesize 3D shapes have made 3D models widespread in various fields including medical research, biology, engineering, etc. 3D shape descriptors play a fundamental role in many 3D shape analysis tasks such as point matching, establishing point-to-point correspondence, shape segmentation and labelling, and shape retrieval to name a few. Various methods have been proposed to calculate succinct and informative descriptors for 3D models. Emerging data-driven techniques use machine learning algorithms to construct accurate and reliable shape descriptors. This survey provides a thorough review of the data-driven 3D shape descriptors from the machine learning point of view and compares them in different criteria. Also, a comprehensive taxonomy of the existing descriptors is proposed based on the exploited machine learning algorithms. Advantages and disadvantages of each category have been discussed in detail. Besides, two alternative categorizations from the data type and the application perspectives are presented. Finally, some directions for possible future research are also suggested. © 2018 The Authors Computer Graphics Forum © 2018 The Eurographics Association and John Wiley & Sons Ltd.},
author_keywords={Categories and Subject Descriptors (according to ACM CCS): I.3.3 [Computer Graphics]: Picture/Image Generation–Line and curve generation;  methods and applications;  modelling},
publisher={Blackwell Publishing Ltd},
issn={01677055},
coden={CGFOD},
language={English},
document_type={Article},
source={Scopus},
}

@BOOK{Goel2019602,
author={Goel, A.K. and Davies, J.},
title={Artificial intelligence},
journal={The Cambridge Handbook of Intelligence},
year={2019},
pages={602-625},
doi={10.1017/9781108770422.026},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098308989&doi=10.1017%2f9781108770422.026&partnerID=40&md5=230d44a6d8a1e7c2c3243211954c9fe3},
abstract={Artificial intelligence (AI) is a scientific discipline that seeks to understand intelligence through the design and construction of intelligent machines. AI and cognitive science have a strong two-way relationship: Cognitive psychology often has inspired AI theories, and AI research has led to new theories of cognition that have been tested through psychological experimentation. While AI theories of cognition often are under-constrained, cognitive theories of AI tend to be over-constrained. Nevertheless, AI is useful for cognitive psychologists both as a source of new ideas and insights, and an experimental testbed. In this chapter, we describe some of the basic concepts and methods of AI by taking robot navigation in a city as an illustrative example. We also briefly discuss the history of AI, methods for assessing progress in AI, and some of AI’s potential impacts on society. © Cambridge University Press 2020.},
publisher={Cambridge University Press},
isbn={9781108755818; 9780511977244},
language={English},
document_type={Book Chapter},
source={Scopus},
}

@BOOK{Freed20191,
author={Freed, S.},
title={AI and human thought and emotion},
journal={AI and Human Thought and Emotion},
year={2019},
pages={1-252},
doi={10.1201/9780429001123},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076142320&doi=10.1201%2f9780429001123&partnerID=40&md5=80961404f584318b54aecdc5570abe77},
abstract={The field of artificial intelligence (AI) has grown dramatically in recent decades from niche expert systems to the current myriad of deep machine learning applications that include personal assistants, natural-language interfaces, and medical, financial, and traffic management systems. This boom in AI engineering masks the fact that all current AI systems are based on two fundamental ideas: mathematics (logic and statistics, from the 19th century), and a grossly simplified understanding of biology (mainly neurons, as understood in 1943). This book explores other fundamental ideas that have the potential to make AI more anthropomorphic. Most books on AI are technical and do not consider the humanities. Most books in the humanities treat technology in a similar manner. AI and Human Thought and Emotion, however is about AI, how academics, researchers, scientists, and practitioners came to think about AI the way they do, and how they can think about it afresh with a humanities-based perspective. The book walks a middle line to share insights between the humanities and technology. It starts with philosophy and the history of ideas and goes all the way to usable algorithms. Central to this work are the concepts of introspection, which is how consciousness is viewed, and consciousness, which is accessible to humans as they reflect on their own experience. The main argument of this book is that AI based on introspection and emotion can produce more human-like AI. To discover the connections among emotion, introspection, and AI, the book travels far from technology into the humanities and then returns with concrete examples of new algorithms. At times philosophical, historical, and technical, this exploration of human emotion and thinking poses questions and provides answers about the future of AI. © 2020 by Taylor & Francis Group, LLC.},
publisher={CRC Press},
isbn={9780429672682; 9780367029296},
language={English},
document_type={Book},
source={Scopus},
}

@CONFERENCE{Anas2019,
author={Anas, E.R. and Guo, L. and Onsy, A. and Matuszewski, B.J.},
title={Scene disparity estimation with convolutional neural networks},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2019},
volume={11059},
doi={10.1117/12.2527628},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072633113&doi=10.1117%2f12.2527628&partnerID=40&md5=49d2ade7bdd8e0aa3c1cd948c0d9f4e4},
abstract={Estimation of stereovision disparity maps is important for many applications that require information about objects’ position and geometry. For example, as depth surrogate, disparity maps are essential for objects’ 3D shape reconstruction and indeed other applications that do require three-dimensional representation of a scene. Recently, deep learning (DL) methodology has enabled novel approaches for the disparity estimation with some focus on the real-time processing requirement that is critical for applications in robotics and autonomous navigation. Previously, that constraint was not always addressed. Furthermore, for robust disparity estimation the occlusion effects should be explicitly modelled. In the described method, the effective detection of occlusion regions is achieved through disparity estimation in both, forward and backward correspondence model with two matching deep subnetworks. These two subnetworks are trained jointly in a single training process. Initially the subnetworks are trained using simulated data with the know ground truth, then to improve generalisation properties the whole model is fine-tuned in an unsupervised fashion on real data. During the unsupervised training, the model is equipped with bilinear interpolation warping function to directly measure quality of the correspondence with the disparity maps estimated for both the left and right image. During this phase forward-backward consistency constraint loss function is also applied to regularise the disparity estimators for non-occluding pixels. The described network model computes, at the same time, the forward and backward disparity maps as well as corresponding occlusion masks. It showed improved results on simulated and real images with occluded objects, when compared with the results obtained without using the forward-backward consistency constraint loss function. © 2019 SPIE.},
author_keywords={Deep learning;  Disparity estimation;  Occlusion detection;  Structural similarity index;  Unsupervised learning},
publisher={SPIE},
issn={0277786X},
isbn={9781510627970},
coden={PSISD},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{García-Martín2019,
author={García-Martín, Á. and Sanmiguel, J.C. and Martínez, J.M.},
title={Coarse-to-fine adaptive people detection for video sequences by maximizing mutual information},
journal={Sensors (Switzerland)},
year={2019},
volume={19},
number={1},
doi={10.3390/s19010004},
art_number={4},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058918753&doi=10.3390%2fs19010004&partnerID=40&md5=275799d21c7b0ab35776c2604a6a8e5e},
abstract={Applying people detectors to unseen data is challenging since patterns distributions, such as viewpoints, motion, poses, backgrounds, occlusions and people sizes, may significantly differ from the ones of the training dataset. In this paper, we propose a coarse-to-fine framework to adapt frame by frame people detectors during runtime classification, without requiring any additional manually labeled ground truth apart from the offline training of the detection model. Such adaptation make use of multiple detectors mutual information, i.e., similarities and dissimilarities of detectors estimated and agreed by pair-wise correlating their outputs. Globally, the proposed adaptation discriminates between relevant instants in a video sequence, i.e., identifies the representative frames for an adaptation of the system. Locally, the proposed adaptation identifies the best configuration (i.e., detection threshold) of each detector under analysis, maximizing the mutual information to obtain the detection threshold of each detector. The proposed coarse-to-fine approach does not require training the detectors for each new scenario and uses standard people detector outputs, i.e., bounding boxes. The experimental results demonstrate that the proposed approach outperforms state-of-the-art detectors whose optimal threshold configurations are previously determined and fixed from offline training data. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.},
author_keywords={Coarse-to-fine adaptation;  Detector adaptation;  Entropy;  Pair-wise correlation;  People detection;  Thresholds},
publisher={MDPI AG},
issn={14248220},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Depierre20183511,
author={Depierre, A. and Dellandrea, E. and Chen, L.},
title={Jacquard: A Large Scale Dataset for Robotic Grasp Detection},
journal={IEEE International Conference on Intelligent Robots and Systems},
year={2018},
pages={3511-3516},
doi={10.1109/IROS.2018.8593950},
art_number={8593950},
note={cited By 60},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062993135&doi=10.1109%2fIROS.2018.8593950&partnerID=40&md5=f2fd5b3a63f2699ec87019cb48dbe89c},
abstract={Grasping skill is a major ability that a wide number of real-life applications require for robotisation. State-of-the-art robotic grasping methods perform prediction of object grasp locations based on deep neural networks. However, such networks require huge amount of labeled data for training making this approach often impracticable in robotics. In this paper, we propose a method to generate a large scale synthetic dataset with ground truth, which we refer to as the Jacquard grasping dataset. Jacquard is built on a subset of ShapeNet, a large CAD models dataset, and contains both RGB-D images and annotations of successful grasping positions based on grasp attempts performed in a simulated environment. We carried out experiments using an off-the-shelf CNN, with three different evaluation metrics, including real grasping robot trials. The results show that Jacquard enables much better generalization skills than a human labeled dataset thanks to its diversity of objects and grasping positions. For the purpose of reproducible research in robotics, we are releasing along with the Jacquard dataset a web interface for researchers to evaluate the successfulness of their grasping position detections using our dataset. © 2018 IEEE.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={21530858},
isbn={9781538680940},
coden={85RBA},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Pandey2018859,
author={Pandey, A. and Puri, M. and Varde, A.},
title={Object detection with neural models, deep learning and common sense to aid smart mobility},
journal={Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI},
year={2018},
volume={2018-November},
pages={859-863},
doi={10.1109/ICTAI.2018.00134},
art_number={8576132},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060807147&doi=10.1109%2fICTAI.2018.00134&partnerID=40&md5=4ead1105aa6a392d8d1bcdb0394e0af4},
abstract={The advent of autonomous transportation systems is attracting attention in AI today. Despite how far this area has progressed, there are situations better handled by humans. One of these is distinguishing objects seen for the first time and making decisions accordingly. Hence, our focus in this paper is on object detection, which can potentially enhance autonomous driving and other types of automation in transportation systems. This impacts Smart Mobility in Smart Cities. We provide expanded analysis of recent object detection techniques including neural models, deep learning and related advances. We highlight a novel object detection system called YOLO (You Only Look Once) and conduct its performance evaluation on real-time data. We point out challenges in this field and then explore the use of Commonsense Knowledge (CSK) in object detection with neural models and deep learning, emphasizing the importance of CSK to capture intuitive human reasoning. We explain how this work would potentially enhance autonomous vehicles and transportation systems. This work thus constitutes an exploratory paper that embodies a vision in Smart Mobility. © 2018 IEEE.},
author_keywords={Autonomous Vehicles;  Commonsense Knowledge;  Image Recognition;  Smart Cities;  Transportation},
publisher={IEEE Computer Society},
issn={10823409},
isbn={9781538674499},
coden={PCTIF},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Rotich2018,
author={Rotich, G. and Aakur, S. and Minetto, R. and Segundo, M.P. and Sarkar, S.},
title={Using Semantic Relationships among Objects for Geospatial Land Use Classification},
journal={Proceedings - Applied Imagery Pattern Recognition Workshop},
year={2018},
volume={2018-October},
doi={10.1109/AIPR.2018.8707405},
art_number={8707405},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065962270&doi=10.1109%2fAIPR.2018.8707405&partnerID=40&md5=f87bc2770adc49ab73d2f4eacc212ffa},
abstract={The geospatial land recognition is often cast as a local-region based classification problem. We show in this work, that prior knowledge, in terms of global semantic relationships among detected regions, allows us to leverage semantics and visual features to enhance land use classification in aerial imagery. To this end, we first estimate the top-k labels for each region using an ensemble of CNNs called Hydra. Twelve different models based on two state-of-the-art CNN architectures, ResNet and DenseNet, compose this ensemble. Then, we use Grenander's canonical pattern theory formalism coupled with the common-sense knowledge base, ConceptNet, to impose context constraints on the labels obtained by deep learning algorithms. These constraints are captured in a multi-graph representation involving generators and bonds with a flexible topology, unlike an MRF or Bayesian networks, which have fixed structures. Minimizing the energy of this graph representation results in a graphical representation of the semantics in the given image. We show our results on the recent fMoW challenge dataset. It consists of 1,047,691 images with 62 different classes of land use, plus a false detection category. The biggest improvement in performance with the use of semantics was for false detections. Other categories with significantly improved performance were: zoo, nuclear power plant, park, police station, and space facility. For the subset of fMow images with multiple bounding boxes the accuracy is 72.79% without semantics and 74.06% with semantics. Overall, without semantic context, the classification performance was 77.04%. With semantics, it reached 77.98%. Considering that less than 20% of the dataset contained more than one ROI for context, this is a significant improvement that shows the promise of the proposed approach. © 2018 IEEE.},
author_keywords={convolutional neural networks;  pattern theory;  Remote sensing},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={21642516},
isbn={9781538693063},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kovács2018353,
author={Kovács, L. and Varga, E.B. and Balla, T.},
title={Efficiency analysis of ontology servers},
journal={Proceedings of the 2018 19th International Carpathian Control Conference, ICCC 2018},
year={2018},
pages={353-358},
doi={10.1109/CarpathianCC.2018.8399655},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050211781&doi=10.1109%2fCarpathianCC.2018.8399655&partnerID=40&md5=9b6b97d55e232c50af519e845de6704d},
abstract={One of the main current trends in the ICT sector is the widespread use of intelligent devices. We can witness the expansion of the IoT architecture where smart devices can interact with each other and they can operate as intelligent agents to control our environment. Usually, these devices have a local knowledge base providing information for the concrete actions. In order to implement a higher level of intelligence, the devices should interact with humans in a more general environment. The main representation form of common sense knowledge in intelligent applications is ontology. Consequently, a widescope and detailed knowledge base that can cover general requirements should be stored in a general ontology server. This means that ontology databases should be able to manage huge amount of data in an efficient way. Although the concept of computerized ontology management is almost 10 years old (Gruber introduced this term in 2009), currently we have experiences only with smaller and separate ontologies. We can expect though that the future development trends in IoT will require the implementation of new kinds of large scale ontology servers, too. This paper presents first the main requirements on a general ontology server focusing on the demands in an IoT architecture. The main goal of the paper is then to compare the efficiency of three implementation alternatives: native RDF triplet storage, relational database storage and graph database storage. © 2018 IEEE.},
author_keywords={IoT;  IoT ontology;  ontology;  ontology server;  semantic database},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538647622},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Persaud20181008,
author={Persaud, P. and Varde, A.S. and Robila, S.},
title={Enhancing autonomous vehicles with commonsense: Smart mobility in smart cities},
journal={Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI},
year={2018},
volume={2017-November},
pages={1008-1012},
doi={10.1109/ICTAI.2017.00155},
note={cited By 13},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048459877&doi=10.1109%2fICTAI.2017.00155&partnerID=40&md5=7ec7e88902c95b315be92da949595c2e},
abstract={Recent advances in AI include a Law firm hiring a robot lawyer and companies developing autonomous vehicles with robot drivers. Findings from our study have gauged the current cognitive capacity of such systems, indicating areas for improvement. We focus on autonomous vehicles, i.e., those that conduct automated driving and need to make autonomous, i.e., independent decisions. We propose an approach enabled with commonsense knowledge (CSK) from worldwide repositories to simulate intuitive humanlike decision-making in autonomous vehicles. We consider the repository WebChild with a multitude of CSK concepts, properties and relations. We investigate this and related domain-specific knowledge bases (domain KBs) to harness them within our proposed approach. Accordingly we build a transportation domain KB incorporating CSK and the needs of autonomous vehicles. This would be useful in guiding automated driving and making the systems get closer to the thresholds of human cognition. This work thereby makes contributions to smart mobility in smart cities. The paper presents our vision with design, implementation, experiments, recommendations and a future roadmap. As a broader impact, it propels more joint work between AI, Law and related areas. © 2017 IEEE.},
author_keywords={AI and law;  Automated driving;  Commonsense Knowledge;  Domain KBs;  Object detection;  Smart mobility},
publisher={IEEE Computer Society},
issn={10823409},
isbn={9781538638767},
coden={PCTIF},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Patnaik201879,
author={Patnaik, L.M. and Kallimani, J.S.},
title={Promises and limitations of conscious machines},
journal={Self, Culture and Consciousness: Interdisciplinary Convergences on Knowing and Being},
year={2018},
pages={79-92},
doi={10.1007/978-981-10-5777-9_5},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046280096&doi=10.1007%2f978-981-10-5777-9_5&partnerID=40&md5=e8e1796d12ae5a261b8215927ea15ca8},
publisher={Springer Singapore},
isbn={9789811057779; 9789811057762},
language={English},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Jebbara2018139,
author={Jebbara, S. and Basile, V. and Cabrio, E. and Cimiano, P.},
title={Extracting common sense knowledge via triple ranking using supervised and unsupervised distributional models},
journal={Semantic Web},
year={2018},
volume={10},
number={1},
pages={139-158},
doi={10.3233/SW-180302},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059637170&doi=10.3233%2fSW-180302&partnerID=40&md5=9480984eb72b04ccf6ee690cdf91f128},
abstract={In this paper we are concerned with developing information extraction models that support the extraction of common sense knowledge from a combination of unstructured and semi-structured datasets. Our motivation is to extract manipulation-relevant knowledge that can support robots' action planning. We frame the task as a relation extraction task and, as proof-of-concept, validate our method on the task of extracting two types of relations: locative and instrumental relations. The locative relation relates objects to the prototypical places where the given object is found or stored. The second instrumental relation relates objects to their prototypical purpose of use. While we extract these relations from text, our goal is not to extract specific textual mentions, but rather, given an object as input, extract a ranked list of locations and uses ranked by 'prototypicality'. We use distributional methods in embedding space, relying on the well-known skip-gram model to embed words into a low-dimensional distributional space, using cosine similarity to rank the various candidates. In addition, we also present experiments that rely on the vector space model NASARI, which compute embeddings for disambiguated concepts and are thus semantically aware. While this distributional approach has been published before, we extend our framework by additional methods relying on neural networks that learn a score to judge whether a given candidate pair actually expresses a desired relation. The network thus learns a scoring function using a supervised approach. While we use a ranking-based evaluation, the supervised model is trained using a binary classification task. The resulting score from the neural network and the cosine similarity in the case of the distributional approach are both used to compute a ranking. We compare the different approaches and parameterizations thereof on the task of extracting the above mentioned relations. We show that the distributional similarity approach performs very well on the task. The best performing parameterization achieves an NDCG of 0.913, a Precision@1 of 0.400 and a Precision@3 of 0.423. The performance of the supervised learning approach, in spite of having being trained on positive and negative examples of the relation in question, is not as good as expected and achieves an NCDG of 0.908, a Precision@1 of 0.454 and a Precision@3 of 0.387, respectively. © 2019 - IOS Press and the authors. All rights reserved.},
author_keywords={commonsense knowledge;  distributional semantics;  Relation extraction;  supervised learning},
publisher={IOS Press BV},
issn={15700844},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Basile201863,
author={Basile, V. and Cabrio, E. and Gandon, F. and Nozza, D.},
title={Mapping natural language labels to structured web resources},
journal={CEUR Workshop Proceedings},
year={2018},
volume={2244},
pages={63-75},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057780706&partnerID=40&md5=b444fb9dd9fb3f56cbd0bb468699a5e3},
abstract={Mapping natural language terms to a Web knowledge base enriches information systems without additional context, with new relations and properties from the Linked Open Data. In this paper we formally define such task, which is related to word sense disambiguation, named entity recognition and ontology matching. We provide a manually annotated dataset of labels linked to DBpedia as a gold standard for evaluation, and we use it to experiment with a number of methods, including a novel algorithm that leverages the specific characteristics of the mapping task. The empirical evidence confirms that general term mapping is a hard task, that cannot be easily solved by applying existing methods designed for related problems. However, incorporating NLP ideas such as representing the context and a proper treatment of multiword expressions can significantly boost the performance, in particular the coverage of the mapping. Our findings open up the challenge to find new ways of approaching term mapping to Web resources and bridging the gap between natural language and the Semantic Web. © 2018 CEUR-WS. All rights reserved.},
publisher={CEUR-WS},
issn={16130073},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Huang2018194,
author={Huang, S. and Qi, S. and Zhu, Y. and Xiao, Y. and Xu, Y. and Zhu, S.-C.},
title={Holistic 3D scene parsing and reconstruction from a single RGB image},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={11211 LNCS},
pages={194-211},
doi={10.1007/978-3-030-01234-2_12},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055096002&doi=10.1007%2f978-3-030-01234-2_12&partnerID=40&md5=08d69e089f3629f0a76a95dd621e5f83},
abstract={We propose a computational framework to jointly parse a single RGB image and reconstruct a holistic 3D configuration composed by a set of CAD models using a stochastic grammar model. Specifically, we introduce a Holistic Scene Grammar (HSG) to represent the 3D scene structure, which characterizes a joint distribution over the functional and geometric space of indoor scenes. The proposed HSG captures three essential and often latent dimensions of the indoor scenes: (i) latent human context, describing the affordance and the functionality of a room arrangement, (ii) geometric constraints over the scene configurations, and (iii) physical constraints that guarantee physically plausible parsing and reconstruction. We solve this joint parsing and reconstruction problem in an analysis-by-synthesis fashion, seeking to minimize the differences between the input image and the rendered images generated by our 3D representation, over the space of depth, surface normal, and object segmentation map. The optimal configuration, represented by a parse graph, is inferred using Markov chain Monte Carlo (MCMC), which efficiently traverses through the non-differentiable solution space, jointly optimizing object localization, 3D layout, and hidden human context. Experimental results demonstrate that the proposed algorithm improves the generalization ability and significantly outperforms prior methods on 3D layout estimation, 3D object detection, and holistic scene understanding. © Springer Nature Switzerland AG 2018.},
author_keywords={3D scene parsing and reconstruction;  Analysis-by-synthesis;  Holistic Scene Grammar;  Markov chain Monte Carlo},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030012335},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={41st German Conference on Artificial Intelligence, KI 2018},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={11117 LNAI},
page_count={421},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054473434&partnerID=40&md5=6837f216ec0eaf2a7d8a87cb4e1ee858},
abstract={The proceedings contain 35 papers. The special focus in this conference is on Artificial Intelligence. The topics include: A sequence-based neuronal model for mobile robot localization; acquiring knowledge of object arrangements from human examples for household robots; solver tuning and model configuration; condorcet’s jury theorem for consensus clustering; sparse transfer classification for text documents; towards hypervector representations for learning and planning with schemas; learnDiag: A direct diagnosis algorithm based on learned heuristics; assembly planning in cluttered environments through heterogeneous reasoning; extracting planning operators from instructional texts for behaviour interpretation; model checking for coalition announcement logic; risk-sensitivity in simulation based online planning; evolutionary structure minimization of deep neural networks for motion sensor data; knowledge sharing for population based neural network training; limited evaluation evolutionary optimization of large neural networks; Understanding NLP neural networks by the texts they generate; visual search target inference using bag of deep visual words; analysis and optimization of deep counterfactual value networks; a variant of monte-carlo tree search for referring expression generation; preference-based monte carlo tree search; probabilistic belief revision via similarity of worlds modulo evidence; fusing first-order knowledge compilation and the lifted junction tree algorithm; intentional forgetting in artificial intelligence systems: Perspectives and challenges; kinds and aspects of forgetting in common-sense knowledge and belief management; bounded-memory stream processing; an implementation and evaluation of user-centered requirements for smart in-house mobility services; predict the individual reasoner: A new approach; the predictive power of heuristic portfolios in human syllogistic reasoning; acquisition of terminological knowledge in probabilistic description logic.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030001100},
language={English},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Peng2018128,
author={Peng, Z. and Lai, J.},
title={Commonsense-knowledge based inference engine},
journal={Advances in Intelligent Systems and Computing},
year={2018},
volume={579},
pages={128-135},
doi={10.1007/978-981-10-6487-6_16},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032642063&doi=10.1007%2f978-981-10-6487-6_16&partnerID=40&md5=3aa38be95c49b62d0eaca195e212a040},
abstract={Nowadays, more and more industries achieve automatic large-scale production, and also more and more robots undertake the responsibilities of domestic chores. When machines run in industries or robots work in home, they should have abilities to make judgement and abilities to learn from experience, if they want to do their jobs well. In this study, a commonsense knowledge base (CKB) and an inference engine that can support decision making with the commonsense knowledge are built. They can understand human languages, and equip with inferencing abilities, and learning abilities. © Springer Nature Singapore Pte Ltd. 2018.},
author_keywords={Artificial intelligence;  Commonsense base;  Inference engine},
publisher={Springer Verlag},
issn={21945357},
isbn={9789811064869},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Miller2017199,
author={Miller, J.R.},
title={A Knowledge-based model of prose comprehension: Applications to expository Texts},
journal={Understanding Expository Text: A Theoretical and Practical Handbook for Analyzing Explanatory Text},
year={2017},
pages={199-226},
doi={10.4324/9781315099958},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012589206&doi=10.4324%2f9781315099958&partnerID=40&md5=a94af420b1433b45bdeca011af82c8aa},
publisher={Taylor and Francis},
isbn={9781351584654; 9781315099958},
language={English},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Luger2017321,
author={Luger, G.F. and Chakrabarti, C.},
title={From Alan Turing to modern AI: practical solutions and an implicit epistemic stance},
journal={AI and Society},
year={2017},
volume={32},
number={3},
pages={321-338},
doi={10.1007/s00146-016-0646-7},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957010547&doi=10.1007%2fs00146-016-0646-7&partnerID=40&md5=763f54d010eef864c01198d0858836f0},
abstract={It has been just over 100 years since the birth of Alan Turing and more than 65 years since he published in Mind his seminal paper, Computing Machinery and Intelligence (Turing in Computing machinery and intelligence. Oxford University Press, Oxford, 1950). In the Mind paper, Turing asked a number of questions, including whether computers could ever be said to have the power of “thinking” (“I propose to consider the question, Can computers think?”..Alan Turing, Computing Machinery and Intelligence, Mind, 1950). Turing also set up a number of criteria—including his imitation game—under which a human could judge whether a computer could be said to be “intelligent”. Turing’s paper, as well as his important mathematical and computational insights of the 1930s and 1940s led to his popular acclaim as the “Father of Artificial Intelligence”. In the years since his paper was published, however, no computational system has fully satisfied Turing’s challenge. In this paper we focus on a different question, ignored in, but inspired by Turing’s work: How might the Artificial Intelligence practitioner implement “intelligence” on a computational device? Over the past 60 years, although the AI community has not produced a general-purpose computational intelligence, it has constructed a large number of important artifacts, as well as taken several philosophical stances able to shed light on the nature and implementation of intelligence. This paper contends that the construction of any human artifact includes an implicit epistemic stance. In AI this stance is found in commitments to particular knowledge representations and search strategies that lead to a product’s successes as well as its limitations. Finally, we suggest that computational and human intelligence are two different natural kinds, in the philosophical sense, and elaborate on this point in the conclusion. © 2016, Springer-Verlag London.},
author_keywords={Artificial intelligence;  Computational intelligence;  Epistemic stance},
publisher={Springer London},
issn={09515666},
language={English},
document_type={Article},
source={Scopus},
}

@ARTICLE{Ohlsson2017679,
author={Ohlsson, S. and Sloan, R.H. and Turán, G. and Urasky, A.},
title={Measuring an artificial intelligence system’s performance on a Verbal IQ test for young children*},
journal={Journal of Experimental and Theoretical Artificial Intelligence},
year={2017},
volume={29},
number={4},
pages={679-693},
doi={10.1080/0952813X.2016.1213060},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980332149&doi=10.1080%2f0952813X.2016.1213060&partnerID=40&md5=017d04a72becc74915b0ad96edc935c2},
abstract={We administered the Verbal IQ (VIQ) part of the Wechsler Preschool and Primary Scale of Intelligence (WPPSI-III) to the ConceptNet 4 artificial intelligence (AI) system. The test questions (e.g. “Why do we shake hands?”) were translated into ConceptNet 4 inputs using a combination of the simple natural language processing tools that come with ConceptNet together with short Python programs that we wrote. The question answering used a version of ConceptNet based on spectral methods. The ConceptNet system scored a WPPSI-III VIQ that is average for a four-year-old child, but below average for 5–7 year olds. Large variations among subtests indicate potential areas of improvement. In particular, results were strongest for the Vocabulary and Similarities subtests, intermediate for the Information subtest and lowest for the Comprehension and Word Reasoning subtests. Comprehension is the subtest most strongly associated with common sense. The large variations among subtests and ordinary common sense strongly suggest that the WPPSI-III VIQ results do not show that “ConceptNet has the verbal abilities of a four-year-old”. Rather, children’s IQ tests offer one objective metric for the evaluation and comparison of AI systems. Also, this work continues previous research on psychometric AI. © 2016 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={Common sense reasoning;  intelligence tests;  IQ tests;  psychometric AI;  test-based AI},
publisher={Taylor and Francis Ltd.},
issn={0952813X},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Valipour201797,
author={Valipour, M. and Wang, Y. and Zatarain, O.A. and Gavrilova, M.L.},
title={Algorithms for determining semantic relations of formal concepts by cognitive machine learning based on concept algebra},
journal={Proceedings of 2016 IEEE 15th International Conference on Cognitive Informatics and Cognitive Computing, ICCI*CC 2016},
year={2017},
pages={97-105},
doi={10.1109/ICCI-CC.2016.7862021},
art_number={7862021},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016167034&doi=10.1109%2fICCI-CC.2016.7862021&partnerID=40&md5=c63a36da2da3f4b38d216be5a47534a0},
abstract={It is recognized that the semantic space of knowledge is a hierarchical concept network. This paper presents theories and algorithms of hierarchical concept classification by quantitative semantic relations via machine learning based on concept algebra. The equivalence between formal concepts are analyzed by an Algorithm of Concept Equivalence Analysis (ACEA), which quantitatively determines the semantic similarity of an arbitrary pair of formal concepts. This leads to the development of the Algorithm of Relational Semantic Classification (ARSC) for hierarchically classify any given concept in the semantic space of knowledge. Experiments applying Algorithms ACEA and ARSC on 20 formal concepts are successfully conducted, which encouragingly demonstrate the deep machine understanding of semantic relations and their quantitative weights beyond human perspectives on knowledge learning and natural language processing. © 2016 IEEE.},
author_keywords={Cognitive algorithms;  Cognitive machine learning;  Concept algebra;  Concept classification;  Concept hierarchy;  Concept similarity;  Formal concept;  Knowledge representation;  Semantic analysis},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509038466},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Taylor20174154,
author={Taylor, J.M. and Raskin, V. and Hickman, L.C.},
title={Accessing implicit meaning: Towards computational ability to reconstruct textual omissions},
journal={2016 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2016 - Conference Proceedings},
year={2017},
pages={4154-4159},
doi={10.1109/SMC.2016.7844883},
art_number={7844883},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015803311&doi=10.1109%2fSMC.2016.7844883&partnerID=40&md5=6c891af11d136c1e8fa1833b0911c9f7},
abstract={This paper describes an early step in approaching implicit meaning computationally. It outlines various types of implicit meanings and then presents a method of finding the so called defaults - omissions that are universally reconstructable and, of course, interpretible without much additional reasoning. The defaults are analyzed on the example of the 1000 instances of TerminateLife events, and a small illustrative experiment is described, where defaults of the event and its children are computationally recovered. © 2016 IEEE.},
author_keywords={Implicit meaning;  Ontological defaults;  Ontology},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509018970},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kim20174188,
author={Kim, M.-J. and Baek, S.-H. and Cho, S.-H. and Kim, J.-H.},
title={Approach to integrate episodic memory into cogency-based behavior planner for robots},
journal={2016 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2016 - Conference Proceedings},
year={2017},
pages={4188-4193},
doi={10.1109/SMC.2016.7844889},
art_number={7844889},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015758789&doi=10.1109%2fSMC.2016.7844889&partnerID=40&md5=ef71eb2f872b44b3be63ad0429fb29d1},
abstract={This paper proposes a novel scheme of integrating episodic memory into semantic memory based task planner. Task planners have taken an important role in AI research along with semantic memory to better perform tasks for robots. Episodic memory memorizes and retrieves temporal sequence of situated behaviors by which temporal relationship between behaviors can be defined. None of any research, however, has implemented it into their work for task planning. By introducing episodic memory into task planner, the temporal causal relationship between situated behaviors, which are stored in semantic memory, is taken into consideration. The integrated architecture proves its effectiveness by notably reducing the number of nodes traversed in finding solutions. Robots can reduce time complexity in solving given problems by retrieving previous memories. Deep Adaptive Resonance Theory (Deep-ART) neural model and cogency-based hierarchical behavior planner are used for the episodic memory and the task planner, respectively. Cogency-based hierarchical behavior planner proves its capability of solving given problems in experiment with humanoid robot Mybot, and Deep-ART is augmented to the planner and tested in simulations. Therefore, the contribution of this approach lies on developing a framework which takes advantage of implementing episodic memory and planner in one place. © 2016 IEEE.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509018970},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Icarte20171283,
author={Icarte, R.T. and Baier, J.A. and Ruz, C. and Soto, A.},
title={How a general-purpose commonsense ontology can improve performance of learning-based image retrieval},
journal={IJCAI International Joint Conference on Artificial Intelligence},
year={2017},
volume={0},
pages={1283-1289},
doi={10.24963/ijcai.2017/178},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031898821&doi=10.24963%2fijcai.2017%2f178&partnerID=40&md5=f01f4f830f1425981b29eac04b69acbb},
abstract={The knowledge representation community has built general-purpose ontologies which contain large amounts of commonsense knowledge over relevant aspects of the world, including useful visual information, e.g.: "a ball is used by a football player", "a tennis player is located at a tennis court". Current state-of-the-art approaches for visual recognition do not exploit these rule-based knowledge sources. Instead, they learn recognition models directly from training examples. In this paper, we study how general-purpose ontologies-specifically, MIT's ConceptNet ontology-can improve the performance of state-of-the-art vision systems. As a testbed, we tackle the problem of sentence-based image retrieval. Our retrieval approach incorporates knowledge from ConceptNet on top of a large pool of object detectors derived from a deep learning technique. In our experiments, we show that ConceptNet can improve performance on a common benchmark dataset. Key to our performance is the use of the ESPGAME dataset to select visually relevant relations from ConceptNet. Consequently, a main conclusion of this work is that general-purpose commonsense ontologies improve performance on visual reasoning tasks when properly filtered to select meaningful visual relations.},
publisher={International Joint Conferences on Artificial Intelligence},
issn={10450823},
isbn={9780999241103},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Shah20171,
author={Shah, A. and Basile, V. and Cabrio, E. and Sowmya Kamath, S.},
title={Frame instance extraction and clustering for default knowledge building},
journal={CEUR Workshop Proceedings},
year={2017},
volume={1935},
pages={1-10},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030764550&partnerID=40&md5=a3095ef28824c359eb27146c56fe5b69},
abstract={Obtaining and representing common-sense knowledge, useful in a robotics scenario for planning and making inference about the robots' surroundings, is a challenging problem, because such knowledge is typically found in unstructured repositories such as text corpora or small handmade resources. The work described in this paper presents a methodology for automatically creating a default knowledge base about real-world objects for the robotics domain. The proposed method relies on clustering frame instances extracted from natural language text as a way of distilling default knowledge. We collect and parse a natural language corpus using the Web as a source, then perform an agglomerative clustering of frame instances according to an appropriately defined similarity measure, and finally extract prototypical frame instances from each cluster and publish them in LOD-complaint format to promote reuse and interoperability.},
publisher={CEUR-WS},
issn={16130073},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Chen2017,
author={Chen, X. and Tang, J. and Li, C.},
title={Progressive 3D shape abstraction via hierarchical CSG tree},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2017},
volume={10443},
doi={10.1117/12.2280270},
art_number={1044315},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021884374&doi=10.1117%2f12.2280270&partnerID=40&md5=016f19bc9d268035c206b0d460f5333b},
abstract={A constructive solid geometry(CSG) tree model is proposed to progressively abstract 3D geometric shape of general object from 2D image. Unlike conventional ones, our method applies to general object without the need for massive CAD models, and represents the object shapes in a coarse-To-fine manner that allows users to view temporal shape representations at any time. It stands in a transitional position between 2D image feature and CAD model, benefits from state-of-The-Art object detection approaches and better initializes CAD model for finer fitting, estimates 3D shape and pose parameters of object at different levels according to visual perception objective, in a coarse-To-fine manner. Two main contributions are the application of CSG building up procedure into visual perception, and the ability of extending object estimation result into a more flexible and expressive model than 2D/3D primitive shapes. Experimental results demonstrate the feasibility and effectiveness of the proposed approach. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.},
author_keywords={3D Reconstruction;  3D Shape Estimation;  CSG;  Hierarchical Representation},
publisher={SPIE},
issn={0277786X},
isbn={9781510613508},
coden={PSISD},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Yamamoto2016616,
author={Yamamoto, M. and Hagiwara, M.},
title={A Moral Judgment System Using an Automatic Created Moral Corpus},
journal={Proceedings - 2016 Joint 8th International Conference on Soft Computing and Intelligent Systems and 2016 17th International Symposium on Advanced Intelligent Systems, SCIS-ISIS 2016},
year={2016},
pages={616-621},
doi={10.1109/SCIS-ISIS.2016.0134},
art_number={7801721},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010450447&doi=10.1109%2fSCIS-ISIS.2016.0134&partnerID=40&md5=c7f5e044c3e7d92f2302630f4308b158},
abstract={In this paper, we propose a moral judgment system using an automatic created moral corpus. The moral corpus enables that the correct judgment to the case that the existing methods cannot judge correctly. Here, the moral corpus means the set of sentences that are labeled 'positive' or 'negative' from the point of view of morality. In the proposed system, the moral corpus is created automatically from a large web corpus using lexical patterns and evaluation expressions. The moral corpus which contains about 300,000 instances was created. After that, a supervised learning is performed using the moral corpus. In the experiments, we compared the proposed system with judgments by human. The results of our experiments indicate that our method significantly outperforms the existing method which is based on the co-occurrence frequency. © 2016 IEEE.},
author_keywords={moral judgment;  text mining;  web corpus},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467390415},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Wang201613,
author={Wang, Y. and Valipour, M. and Zatarain, O.A.},
title={Quantitative semantic analysis and comprehension by cognitive machine learning},
journal={International Journal of Cognitive Informatics and Natural Intelligence},
year={2016},
volume={10},
number={3},
pages={13-28},
doi={10.4018/IJCINI.2016070102},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998631503&doi=10.4018%2fIJCINI.2016070102&partnerID=40&md5=23902cdceb1c0da1be731c121dd1cfb5},
abstract={Knowledge learning is the sixth and the most fundamental category of machine learning mimicking the brain. It is recognized that the semantic space of machine knowledge is a hierarchical concept network (HCN), which can be rigorously represented by formal concepts in concept algebra and semantic algebra. This paper presents theories and algorithms of hierarchical concept classification by quantitative semantic analysis based on machine learning. Semantic equivalence between formal concepts is rigorously measured by an Algorithm of Concept Equivalence Analysis (ACEA). The semantic hierarchy among formal concepts is quantitatively determined by an Algorithm of Relational Semantic Classification (ARSC). Experiments applying Algorithms ACEA and ARSC on a set of formal concepts have been successfully conducted, which demonstrate a deep machine understanding of formal concepts and quantitative relations in the hierarchical semantic space by machine learning beyond human empirical perspectives. Copyright © 2016, IGI Global.},
author_keywords={Algorithms;  Cognitive Learning;  Concept Algebra;  Concept Classification;  Knowledge Learning;  Knowledge Representation;  Machine Learning;  Semantic Algebra;  Semantic Analysis},
publisher={IGI Global},
issn={15573958},
language={English},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kataoka20161,
author={Kataoka, Y. and Nakatsuji, M. and Toda, H. and Koike, Y. and Matsuo, Y.},
title={Extracting and evaluating ontologies of human activities from linked open data and social media},
journal={Transactions of the Japanese Society for Artificial Intelligence},
year={2016},
volume={31},
number={1},
pages={1-12},
doi={10.1527/tjsai.LOD-H-NGC},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076878558&doi=10.1527%2ftjsai.LOD-H-NGC&partnerID=40&md5=3fb153219bf62c0d0a1ec042bade3162},
abstract={Many of the problems we face today in artificial intelligence, e.g., real-world activity navigation, can only be solved if we have adequate knowledge bases of human behavior. Although some of the knowledge is available as Linked Open Data (LOD), the amount of data that is available is not enough to realize truly useful navigation applications. The purpose of this paper is to propose and evaluate a method that can automatically extract an ontology of human activities. This ontology is composed of a graph based on ConceptNet5 whose nodes represent activities and whose edges represent semantics between activities. The challenges to developing a truly useful activity navigation system are the following: (i) improving the currently low coverage rate of extracted activities, and (ii) allowing and predicting multiple semantics between activities. The proposed method has two steps: (1) extract mutually related activities from social media, and (2) predict the semantic label between activities via supervised learning by leveraging the semantics on ConceptNet5 as labeled data. Comparisons with ConceptNet5 show that the proposed method can discover more activities than ConceptNet5 and predict semantic relations between activities more accurately, about 10% more accurately, than the baseline method. © 2016, Japanese Society for Artificial Intelligence. All rights reserved.},
author_keywords={Human activity;  Knowledge acquisition;  Linked Open Data;  Machine learning},
publisher={Japanese Society for Artificial Intelligence},
issn={13460714},
language={Japanese},
document_type={Article},
source={Scopus},
}

@ARTICLE{Ruiz-Sarmiento20163,
author={Ruiz-Sarmiento, J.R. and Galindo, C. and Gonzalez-Jimenez, J.},
title={Probability and common-sense: Tandem towards robust robotic object recognition in ambient assisted living},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={10070 LNCS},
pages={3-8},
doi={10.1007/978-3-319-48799-1_1},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009724194&doi=10.1007%2f978-3-319-48799-1_1&partnerID=40&md5=788b515d2a8f951606f34626abc045b2},
abstract={The suitable operation of mobile robots when providing Ambient Assisted Living (AAL) services calls for robust object recognition capabilities. Probabilistic Graphical Models (PGMs) have become the de-facto choice in recognition systems aiming to efficiently exploit contextual relations among objects, also dealing with the uncertainty inherent to the robot workspace. However, these models can perform in an incoherent way when operating in a long-term fashion out of the laboratory, e.g. while recognizing objects in peculiar configurations or belonging to new types. In this work we propose a recognition system that resorts to PGMs and common-sense knowledge, represented in the form of an ontology, to detect those inconsistencies and learn from them. The utilization of the ontology carries additional advantages, e.g. the possibility to verbalize the robot’s knowledge. A primary demonstration of the system capabilities has been carried out with very promising results. © Springer International Publishing AG 2016.},
author_keywords={AAL;  Environmental information;  Object recognition;  Ontologies;  Probabilistic graphical models;  Robotics},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319487984},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ortiz201655,
author={Ortiz, C.L., Jr.},
title={Why we need a physically embodied turing test and what it might look like},
journal={AI Magazine},
year={2016},
volume={37},
number={1},
pages={55-62},
doi={10.1609/aimag.v37i1.2645},
note={cited By 15},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997393509&doi=10.1609%2faimag.v37i1.2645&partnerID=40&md5=6bf628faa96acf93024318205d9f5c57},
abstract={The Turing test, as originally conceived, focused on language and reasoning; problems of perception and action were conspicuously absent. To serve as a benchmark for motivating and monitoring progress in AI research, this article proposes an extension to that original proposal that incorporates all four of these aspects of intelligence. Some initial suggestions are made regarding how best to structure such a test and how to measure progress. The proposed test also provides an opportunity to bring these four important areas of AI research back into sync after each has regrettably diverged into a fairly independent area of research of its own. Copyright © 2016, Association for the Advancement of Artificial Intelligence. All rights reserved.},
publisher={AI Access Foundation},
issn={07384602},
coden={AIMAE},
language={English},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yumer2016294,
author={Yumer, M.E. and Mitra, N.J.},
title={Learning semantic deformation flows with 3D convolutional networks},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={9910 LNCS},
pages={294-311},
doi={10.1007/978-3-319-46466-4_18},
note={cited By 26},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990043610&doi=10.1007%2f978-3-319-46466-4_18&partnerID=40&md5=8e443c43675e3e1d8bc14f473e7bd0e7},
abstract={Shape deformation requires expert user manipulation even when the object under consideration is in a high fidelity format such as a 3D mesh. It becomes even more complicated if the data is represented as a point set or a depth scan with significant self occlusions. We introduce an end-to-end solution to this tedious process using a volumetric Convolutional Neural Network (CNN) that learns deformation flows in 3D. Our network architectures take the voxelized representation of the shape and a semantic deformation intention (e.g., make more sporty) as input and generate a deformation flow at the output. We show that such deformation flows can be trivially applied to the input shape, resulting in a novel deformed version of the input without losing detail information. Our experiments show that the CNN approach achieves comparable results with state of the art methods when applied to CAD models.When applied to single frame depth scans, and partial/noisy CAD models we achieve ∼60% less error compared to the state-of-the-art. © Springer International Publishing AG 2016.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319464657},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Dash2016477,
author={Dash, S.K. and Pakray, P. and Gelbukh, A.},
title={Learning physiotherapy through virtual action},
journal={Computacion y Sistemas},
year={2016},
volume={20},
number={3},
pages={477-482},
doi={10.13053/CyS-20-3-2450},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989946030&doi=10.13053%2fCyS-20-3-2450&partnerID=40&md5=2d90d572516a7419fd344f00af8d3a66},
abstract={We describe a research framework for virtualizing documented physiotherapy instructions. Our approach bridges the gap between human understanding and the written manuals of instructions for physiotherapy. Techniques of Natural Language Processing involving semantic and spatial information processing are important in this approach. We have also explained the physiotherapy considerations that we employed in this research.},
author_keywords={Natural language processing;  Physiotherapy;  Virtual action},
publisher={Instituto Politecnico Nacional},
issn={14055546},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Mustafa2016164,
author={Mustafa, W. and Wächter, M. and Szedmak, S. and Agostini, A. and Kraft, D. and Asfour, T. and Piater, J. and Wörgötter, F. and Krüger, N.},
title={Affordance estimation for vision-based object replacement on a humanoid robot},
journal={47th International Symposium on Robotics, ISR 2016},
year={2016},
pages={164-172},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983776379&partnerID=40&md5=c41df09cd598d29cb0ec11ec7c1e5889},
abstract={In this paper, we address the problem of finding replacements of missing objects, involved in the execution of manipulation tasks. Our approach is based on estimating functional affordances for the unknown objects in order to propose replacements. We use a vision-based affordance estimation system utilizing object-wise global features and a multi-label learning method. This method also associates confidence values to the estimated affordances. We evaluate our approach on kitchen-related manipulation affordances. The evaluation also includes testing different scenarios for training the system using large-scale datasets. The results indicate that the system is able to successfully predict the affordances of novel objects. We also implement our system on a humanoid robot and demonstrate the affordance estimation in a real scene. © 2016 VDE VERLAG GMBH Berlin Offenbach.},
publisher={VDE Verlag GmbH},
isbn={9783800742318},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Eppe2015720,
author={Eppe, M. and Bhatt, M.},
title={A history based approximate epistemic action theory for efficient postdictive reasoning},
journal={Journal of Applied Logic},
year={2015},
volume={13},
number={4},
pages={720-769},
doi={10.1016/j.jal.2015.08.001},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960472980&doi=10.1016%2fj.jal.2015.08.001&partnerID=40&md5=45d4c90b954847a60c6c83a1bb966656},
abstract={We propose an approximation of the possible worlds semantics (PWS) of knowledge with support for postdiction - a fundamental inference pattern for diagnostic reasoning and explanation tasks in a wide range of real-world applications such as cognitive robotics, visual perception for cognitive vision, ambient intelligence and smart environments. We present the formal framework, an operational semantics, and an analysis of soundness and completeness results therefrom. The advantage of our approach is that only a linear number of state-variables are required to represent an agent's knowledge state. This is achieved by modeling knowledge as the history of a single approximate state, instead of using an exponential number of possible worlds like in Kripke semantics. That is, we add a temporal dimension to the knowledge representation which facilitates efficient postdiction. Since we consider knowledge histories, we call our theory h-approximation (HPX). Due to the linear number of state variables, HPX features a comparably low computational complexity. Specifically, we show that HPX can solve the projection problem in polynomial (tractable) time. It can solve planning problems in NP, while e.g. for the action language Ak [48] this is Σ2P-complete. In addition to the temporal dimension of knowledge, our theory supports concurrent acting and sensing, and is in this sense more expressive than existing approximations. © 2015 Elsevier B.V. All rights reserved.},
author_keywords={Action and change;  Commonsense reasoning;  Epistemic reasoning},
publisher={Elsevier Ltd},
issn={15708683},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Savva201524,
author={Savva, M. and Chang, A.X. and Hanrahan, P.},
title={Semantically-enriched 3D models for common-sense knowledge},
journal={IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
year={2015},
volume={2015-October},
pages={24-31},
doi={10.1109/CVPRW.2015.7301289},
art_number={7301289},
note={cited By 43},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951960741&doi=10.1109%2fCVPRW.2015.7301289&partnerID=40&md5=e9ed548b68346c223201e0047bd32d5e},
abstract={We identify and connect a set of physical properties to 3D models to create a richly-annotated 3D model dataset with data on physical sizes, static support, attachment surfaces, material compositions, and weights. To collect these physical property priors, we leverage observations of 3D models within 3D scenes and information from images and text. By augmenting 3D models with these properties we create a semantically rich, multi-layered dataset of common indoor objects. We demonstrate the usefulness of these annotations for improving 3D scene synthesis systems, enabling faceted semantic queries into 3D model datasets, and reasoning about how objects can be manipulated by people using weight and static friction estimates. © 2015 IEEE.},
author_keywords={Computational modeling;  Data models;  Predictive models;  Semantics;  Solid modeling;  Taxonomy;  Three-dimensional displays},
publisher={IEEE Computer Society},
issn={21607508},
isbn={9781467367592},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lang2015325,
author={Lang, D. and Friedmann, S. and Hedrich, J. and Paulus, D.},
title={Semantic mapping for mobile outdoor robots},
journal={Proceedings of the 14th IAPR International Conference on Machine Vision Applications, MVA 2015},
year={2015},
pages={325-328},
doi={10.1109/MVA.2015.7153196},
art_number={7153196},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941198791&doi=10.1109%2fMVA.2015.7153196&partnerID=40&md5=2d1b03535a23343d4a9ae7ad3c32c80f},
abstract={In this paper we present the concept and realization of a semantic mapping system for a mobile outdoor robot. Semantic maps aim to give robots the ability to gather semantic information about their environment, to store it, represent it for the user, and to perform high-level tasks based on the semantic information. The map is build by a system integrating the combination of object classification and common-sense knowledge. We validate the proposed semantic map representation on a real-world 3D point cloud dataset. The presented classification approach achieves an overall precision about 96 %. The semantic maps result into a data structure which offers the opportunity to solve complex task settings and can be integrated onto real robotic systems. © 2015 MVA organization.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9784901122153},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lifschitz2015163,
author={Lifschitz, V.},
title={The Dramatic True Story of the Frame Default},
journal={Journal of Philosophical Logic},
year={2015},
volume={44},
number={2},
pages={163-176},
doi={10.1007/s10992-014-9332-8},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938196611&doi=10.1007%2fs10992-014-9332-8&partnerID=40&md5=c28205c50211366c319efe789d1ce5d1},
abstract={This is an expository article about the solution to the frame problem proposed in 1980 by Raymond Reiter. For years, his “frame default” remained untested and suspect. But developments in some seemingly unrelated areas of computer science—logic programming and satisfiability solvers—eventually exonerated the frame default and turned it into a basis for important applications. © 2014, Springer Science+Business Media Dordrecht.},
author_keywords={Answer set programming;  Commonsense reasoning;  Default logic;  Frame problem},
publisher={Kluwer Academic Publishers},
issn={00223611},
language={English},
document_type={Article},
source={Scopus},
}

@ARTICLE{Xu2015226,
author={Xu, R. and Chen, T. and Xia, Y. and Lu, Q. and Liu, B. and Wang, X.},
title={Word Embedding Composition for Data Imbalances in Sentiment and Emotion Classification},
journal={Cognitive Computation},
year={2015},
volume={7},
number={2},
pages={226-240},
doi={10.1007/s12559-015-9319-y},
note={cited By 65},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939941491&doi=10.1007%2fs12559-015-9319-y&partnerID=40&md5=d98437aa7bf37f462e7a48a449c22b1a},
abstract={Text classification often faces the problem of imbalanced training data. This is true in sentiment analysis and particularly prominent in emotion classification where multiple emotion categories are very likely to produce naturally skewed training data. Different sampling methods have been proposed to improve classification performance by reducing the imbalance ratio between training classes. However, data sparseness and the small disjunct problem remain obstacles in generating new samples for minority classes when the data are skewed and limited. Methods to produce meaningful samples for smaller classes rather than simple duplication are essential in overcoming this problem. In this paper, we present an oversampling method based on word embedding compositionality which produces meaningful balanced training data. We first use a large corpus to train a continuous skip-gram model to form a word embedding model maintaining the syntactic and semantic integrity of the word features. Then, a compositional algorithm based on recursive neural tensor networks is used to construct sentence vectors based on the word embedding model. Finally, we use the SMOTE algorithm as an oversampling method to generate samples for the minority classes and produce a fully balanced training set. Evaluation results on two quite different tasks show that the feature composition method and the oversampling method are both important in obtaining improved classification results. Our method effectively addresses the data imbalance issue and consequently achieves improved results for both sentiment and emotion classification. © 2015, Springer Science+Business Media New York.},
author_keywords={Emotion classification;  Imbalanced training;  Semantic compositionality;  Sentiment analysis;  Word embedding},
publisher={Springer New York LLC},
issn={18669956},
language={English},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sachnev2015103,
author={Sachnev, V. and Ramasamy, S. and Sundaram, S. and Kim, H.J. and Hwang, H.J.},
title={A Cognitive Ensemble of Extreme Learning Machines for Steganalysis Based on Risk-Sensitive Hinge Loss Function},
journal={Cognitive Computation},
year={2015},
volume={7},
number={1},
pages={103-110},
doi={10.1007/s12559-014-9268-x},
note={cited By 20},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922752943&doi=10.1007%2fs12559-014-9268-x&partnerID=40&md5=0262994a2d63ed0fe303810616982691},
abstract={In this paper, we propose a risk-sensitive hinge loss function-based cognitive ensemble of extreme learning machine (ELM) classifiers for JPEG steganalysis. ELM is a single hidden-layer feed-forward network that chooses the input parameters randomly and estimates the output weights analytically. For steganalysis, we have extracted 548-dimensional merge features and trained ELM to approximate the functional relationship between the merge features and class label. Further, we use a cognitive ensemble of ELM classifier with risk-sensitive hinge loss function for accurate steganalysis. As the hinge loss error function is shown to be better than mean-squared error function for classification problems, here, the individual ELM classifiers are developed based on hinge loss error function. The cognition in the ensemble of ELM obtains the weighted sum of individual classifiers by enhancing the outputs of winning classifiers for a sample, while penalizing the other classifiers for the sample. Thus, the cognitive ensemble ELM classifier positively exploits the effect of initialization in each classifier to obtain the best results. The performance of the cognitive ensemble ELM in performing the steganalysis is compared to that of a single ELM, and the existing ensemble support vector machine classifier for steganalysis. Performance results show the superior classification ability of the cognitive ensemble ELM classifier. © 2014, Springer Science+Business Media New York.},
author_keywords={Extreme learning machine;  JPEG steganography;  Steganalysis;  Undetectable data hiding},
publisher={Springer Science and Business Media, LLC},
issn={18669956},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Cambria2015282,
author={Cambria, E. and Rajagopal, D. and Kwok, K. and Sepulveda, J.},
title={GECKA: Game engine for commonsense knowledge acquisition},
journal={Proceedings of the 28th International Florida Artificial Intelligence Research Society Conference, FLAIRS 2015},
year={2015},
pages={282-287},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958213986&partnerID=40&md5=5dc71004110ba8f5feb6e7c68667690e},
abstract={Commonsense knowledge representation and reasoning is key for tasks such as natural language understanding. Since common-sense consists of information that humans take for granted, however, gathering it is an extremely difficult task. The game engine for commonsense knowledge acquisition (GECKA) aims to collect common-sense from game designers through the development of serious games. GECKA merges, as never before, the potential of serious games and games with a purpose. This not only provides a platform for the acquisition of re-usable and multi-purpose knowledge, but also enables the development of games that can, apart from providing entertainment value, also teach gamers something meaningful about the world they live in. Copyright © 2015, Association for the Advancement of Artificial Intelligence. All rights reserved.},
publisher={AAAI Press},
isbn={9781577357308},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Kolesnikova20153,
author={Kolesnikova, O. and Gelbukh, A.},
title={Measuring non-compositionality of verb-noun collocations using lexical functions and wordnet hypernyms},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9414},
pages={3-25},
doi={10.1007/978-3-319-27101-9_1},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952656126&doi=10.1007%2f978-3-319-27101-9_1&partnerID=40&md5=b2a094ee10102624f868ce9d3f5e0f8d},
abstract={In such verb-noun combinations as draw a conclusion, lend support, take a step, the verb acquires a meaning different from its typical meaning usually represented by the first sense in WordNet thus making a correct compositional analysis hard or even impossible. Such non-compositional word combinations are called collocations. The semantics and syntactical properties of collocations can be formalized using lexical functions, a concept of the Meaning-Text Theory. In this paper we realized two series of experiments, both with supervised learning methods on automatic detection of lexical functions in verb-noun collocations using WordNet hypernyms. In the first experimental series, we used hypernyms which correspond to the manually annotated WordNet senses of verbs and nouns in the dataset. In the second series, we used hypernyms corresponding to the typical (first) sense of the verbs. Comparing the results of both experiments we found that the performance of supervised learning on some lexical functions was better in the second case in spite of the fact that the first sense was not the sense of the verbs they have in collocations. This shows that for such lexical functions, the semantics of the verbs is closer to their typical senses and thus noncompositionality of such collocations is weaker. We propose to use the difference in lexical function detection based on the actual sense and the first sense as a simple measure of non-compositionality of verb-noun collocations. © Springer International Publishing Switzerland 2015.},
author_keywords={Lexical functions;  Non-compositionality of collocations;  Supervised learning;  Verb-noun collocations;  Wordnet hypernyms},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319271002},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Mishra2015257,
author={Mishra, A. and Jain, S.K.},
title={An approach for intention mining of complex comparative opinion why type questions asked on product review sites},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9042},
pages={257-271},
doi={10.1007/978-3-319-18117-2_19},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942546689&doi=10.1007%2f978-3-319-18117-2_19&partnerID=40&md5=1f46ae667e32ae4e99c216fc0cd16822},
abstract={Opinion why-questions require answers to include reasons,elaborations, explanations for the users’ sentiments expressed in the questions.Sentiment analysis has been recently used for answering why type opinionquestions. Existing research addresses simple why-type questions havingdescription of single product in the questions. In real life, there could becomplex why type questions having description of multiple products (asobserved in comparative sentences) given in multiple sentences. For example,the question, “I need mobile with good camera and nice sound quality. Whyshould I go for buying Nokia over Samsung?” Nokia is the main focus for thequestioner who shows positive intention for buying mobile. This calls fornatural requirement for systems to identify the product which is centre ofattention for the questioners and the intention of the questioner towards thesame. We address such complex questions and propose an approach to performintention mining of the questioner by determining the sentiment polarity of thequestioner towards the main focused product. We conduct experiments whichobtain better results as compared to existing baseline systems. © Springer International Publishing Switzerland 2015.},
author_keywords={Information retrieval;  Natural language processing;  Natural language understanding and reasoning;  Question Answering},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319181165},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Parsons2015121,
author={Parsons, B. and Vidal, J.M. and Huynh, N. and Snyder, R.},
title={Automatic generation of agent behavior models from raw observational data},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9002},
pages={121-132},
doi={10.1007/978-3-319-14627-0_9},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927795074&doi=10.1007%2f978-3-319-14627-0_9&partnerID=40&md5=dd1a5bd77b86df8261ca2cba6fbb6537},
abstract={Agent-based modeling is used to simulate human behaviors in different fields. The process of building believable models of human behavior requires that domain experts and Artificial Intelligence experts work closely together to build custom models for each domain, which requires significant effort. The aim of this study is to automate at least some parts of this process. We present an algorithm called magic, which produces an agent behavioral model from raw observational data. It calculates transition probabilities between actions and identifies decision points at which the agent requires additional information in order to choose the appropriate action. Our experiments using synthetically-generated data and real-world data from a hospital setting show that the magic algorithm can automatically produce an agent decision process. The agent’s underlying behavior can then be modified by domain experts, thus reducing the complexity of producing believable agent behavior from field data. © Springer International Publishing Switzerland 2015.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319146263},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Prade20151,
author={Prade, H. and Richard, G.},
title={A short introduction to computational trends in analogical reasoning},
journal={Studies in Computational Intelligence},
year={2015},
volume={548},
pages={1-22},
doi={10.1007/978-3-642-54516-0_1},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926647467&doi=10.1007%2f978-3-642-54516-0_1&partnerID=40&md5=3a50911a101216caa4a30ddce3c88a94},
abstract={For a long time, identifying analogies and reasoning by analogy have been recognized as major cognitive capabilities of human mind. As such, analogy has been widely studied and discussed, in particular by philosophers. More recently, it has attracted a lot of attention in cognitive sciences, and in computer sciences, especially artificial intelligence. The aim of this volume is to report on current advances regarding the computational aspects of analogy. Before presenting the structure and the contents of the book, we provide a short historical account of researches on analogy, focusing on a modeling perspective. © Springer-Verlag Berlin Heidelberg 2014.},
publisher={Springer Verlag},
issn={1860949X},
language={English},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tweedale20151,
author={Tweedale, J.W. and Jain, L.C.},
title={Advances in knowledge-based information systems},
journal={Smart Innovation, Systems and Technologies},
year={2015},
volume={30},
pages={1-18},
doi={10.1007/978-3-319-13545-8_1},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922010611&doi=10.1007%2f978-3-319-13545-8_1&partnerID=40&md5=6df73d3cfe5e6d2578eb3ffcff0352ce},
abstract={History is full of innovative researchers, such as; Aristotle, Newton and Einstien. This cumulative evolutionary of science has stimulated industrial activitiy and ultimately contributes to society. The publication of science also contributes to the body of collective knowledge and enables researchers to build on the success of its pioneers. A sequenced example of fundamental principles, by Ørsted, Faraday and Maxwell, highlights the evolution of electromagnetic induction, from electric currents through to validated concepts associated with Electro-Magnetic Fields (EMF). This chapter documents innovative contributions representing advances in Knowledge-Based and Intelligent Information and Engineering System. New research recognises that society is familiar with modern AIP technology and documents how they routinely incorporate Artificial Intelligence (AI) techniques into industrial applications. There is an increasing reliance on automatically processing declarative knowledge with less human input. Society has already digitised its past and continues to progressively automate knowledge management for future access by mobile systems. This book focuses on this trend and collectively discusses select topics. They are grouped into five categories that include: classifiers, data mining, knowledge management, AIP techniques and a number of models that can be used to solve industrial level problem. Each topic represents the state of art in research by innovative subject matter experts. All five categorise represent a broad spread of topics across the domain and highlight how research is being realised to benefit society. Students, professionals and interested observers within the knowledge-based and intelligent information management domain will benefit from the diversity and richness of the content. © Springer International Publishing Switzerland 2015.},
author_keywords={Artificial Intelligence;  Computational Intelligence;  Evolutionary Computing;  Fuzzy Logic;  Genetic Algorithm;  Machine Intelligence;  Multi-Agent System;  Neural Network},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={21903018},
isbn={9783319135441},
language={English},
document_type={Article},
source={Scopus},
}

@ARTICLE{Xu2014441,
author={Xu, Y.},
title={What can artificial intelligence learn from Wittgenstein's on certainty?},
journal={Frontiers of Philosophy in China},
year={2014},
volume={9},
number={3},
pages={441-462},
doi={10.3868/s030-003-014-0037-9},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923876814&doi=10.3868%2fs030-003-014-0037-9&partnerID=40&md5=cd254bc92195427c8902fff1d26c0fde},
abstract={Meta-philosophically speaking, the philosophy of artificial intelligence (AI) is intended not only to explore the theoretical possibility of building "thinking machines," but also to reveal philosophical implications of specific AI approaches. Wittgenstein's comments on the analytic/empirical dichotomy may offer inspirations for AI in the second sense. According to his "river metaphor" in On Certainty, the analytic/empirical boundary should be delimited in a way sensitive to specific contexts of practical reasoning. His proposal seems to suggest that any cognitive modeling project needs to render the system context-sensitive by avoiding representing large amounts of truisms in its cognitive processes, otherwise neither representational compactness nor computational efficiency can be achieved. In this article, different AI approaches (like the Common Sense Law of Inertia approach, the Bayesian approach and the connectionist approach) will be critically evaluated under the afore-mentioned Wittgensteinian criteria, followed by the author's own constructive suggestion on what AI needs to try to do in the near future.},
author_keywords={analytic/empirical dichotomy;  artificial intelligence;  axiomatic system;  Bayesian network;  connectionism;  context},
publisher={Brill Academic Publishers},
issn={16733436},
language={English},
document_type={Article},
source={Scopus},
}

@BOOK{Raskin2014111,
author={Raskin, V.},
title={Focus, salience, and priming in cyber-physical intelligence},
journal={Applied Cyber-Physical Systems},
year={2014},
volume={9781461473367},
pages={111-124},
doi={10.1007/978-1-4614-7336-7_10},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930436543&doi=10.1007%2f978-1-4614-7336-7_10&partnerID=40&md5=5548ac4a60caf63e805eea643ed6edbc},
abstract={Information and language processing in a growing variety of computer applications can achieve the accuracy/precision and reliability that human users require if based on human-like understanding. While statistical and/or machine learning methods in text processing have been perfected in the last two decades (see, for instance, [1, 2] and references there), their successes have been limited in scope, primarily to the clustering tasks, and even there, the applications have excelled better in recall than in precision, leading to customer disappointments with commercial products. © 2014 Springer Science+Business Media New York. All rights are reserved.},
publisher={Springer New York},
isbn={9781461473367; 1461473357; 9781461473350},
language={English},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Modi2014,
author={Modi, A. and Titov, I.},
title={Learning semantic script knowledge with event embeddings},
journal={2nd International Conference on Learning Representations, ICLR 2014 - Workshop Track Proceedings},
year={2014},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953944&partnerID=40&md5=5232d37a63f245490fa1722882904538},
abstract={Induction of common sense knowledge about prototypical sequences of events has recently received much attention (e.g., (Chambers & Jurafsky, 2008; Regneri et al., 2010)). Instead of inducing this knowledge in the form of graphs, as in much of the previous work, in our method, distributed representations of event realizations are computed based on distributed representations of predicates and their arguments, and then these representations are used to predict prototypical event orderings. The parameters of the compositional process for computing the event representations and the ranking component of the model are jointly estimated from texts. We show that this approach results in a substantial boost in ordering performance with respect to previous methods. © 2014 International Conference on Learning Representations, ICLR. All rights reserved.},
publisher={International Conference on Learning Representations, ICLR},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Najmi2014366,
author={Najmi, E. and Hashmi, K. and Malik, Z. and Rezgui, A. and Khan, H.U.},
title={ConceptOnto: An upper ontology based on ConceptNet},
journal={Proceedings of IEEE/ACS International Conference on Computer Systems and Applications, AICCSA},
year={2014},
volume={2014},
pages={366-372},
doi={10.1109/AICCSA.2014.7073222},
art_number={7073222},
note={cited By 21},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992255255&doi=10.1109%2fAICCSA.2014.7073222&partnerID=40&md5=70531d5a2ff83dfb00be78034130e1df},
abstract={The exponential growth of information has prompted the introduction of new technologies such as Semantic Web and Common Sense knowledge bases. To connect the different knowledge presentations together is a primary requirement, and ontologies are central we need for this transformation. In this paper we introduce ConceptOnto which is an ontology based on the ConceptNet knowledge base with extension of some of the other properties in some of the more acclaimed upper ontologies. Our goal in the creation of ConceptOnto is readability for humans, and maximizing the functionality while saving the generality of the ontology. © 2014 IEEE.},
publisher={IEEE Computer Society},
issn={21615322},
isbn={9781479971008},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Pappu2014194,
author={Pappu, A. and Rudnicky, A.I.},
title={Knowledge acquisition strategies for goal-oriented dialog systems},
journal={SIGDIAL 2014 - 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue, Proceedings of the Conference},
year={2014},
pages={194-198},
doi={10.3115/v1/w14-4326},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960169729&doi=10.3115%2fv1%2fw14-4326&partnerID=40&md5=587de03c2125ebd01d70de7fa675a270},
abstract={Many goal-oriented dialog agents are expected to identify slot-value pairs in a spoken query, then perform lookup in a knowledge base to complete the task. When the agent encounters unknown slotvalues, it may ask the user to repeat or reformulate the query. But a robust agent can proactively seek new knowledge from a user, to help reduce subsequent task failures. In this paper, we propose knowledge acquisition strategies for a dialog agent and show their effectiveness. The acquired knowledge can be shown to subsequently contribute to task completion. © 2014 Association for Computational Linguistics.},
publisher={Association for Computational Linguistics (ACL)},
isbn={9781941643211},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Mühlbacher201449,
author={Mühlbacher, C. and Steinbauer, G.},
title={Using common sense invariants in belief management for autonomous agents},
journal={Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
year={2014},
volume={8481},
pages={49-59},
doi={10.1007/978-3-319-07455-9_6},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958546205&doi=10.1007%2f978-3-319-07455-9_6&partnerID=40&md5=fc7141e39619fde281dd96909349fde7},
abstract={To design a truly autonomous robot it is necessary that the robot is able to handle unexpected action outcomes. One way to deal with these outcomes is to perform a diagnosis on the history of performed actions. Basically there are two ways to trigger such a diagnosis. One way to trigger it is a direct contradiction between a sensor reading and its expected value. Another way is to use background knowledge if an alternative action outcome does not lead to a direct contradiction. In order to avoid the necessity to hand-code this knowledge we propose to reuse a existing common sense knowledge base. In this paper we present an approach for reusing existing common sense knowledge in a belief management approach for autonomous agents. © Springer International Publishing Switzerland 2014.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319074542},
coden={LNAIE},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Modi201449,
author={Modi, A. and Titov, I.},
title={Inducing neural models of script knowledge},
journal={CoNLL 2014 - 18th Conference on Computational Natural Language Learning, Proceedings},
year={2014},
pages={49-57},
doi={10.3115/v1/w14-1606},
note={cited By 45},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958268706&doi=10.3115%2fv1%2fw14-1606&partnerID=40&md5=bae666d449b1931e6706809778d350fc},
abstract={Induction of common sense knowledge about prototypical sequence of events has recently received much attention (e.g., Chambers and Jurafsky (2008); Regneri et al. (2010)). Instead of inducing this knowledge in the form of graphs, as in much of the previous work, in our method, distributed representations of event realizations are computed based on distributed representations of predicates and their arguments, and then these representations are used to predict prototypical event orderings. The parameters of the compositional process for computing the event representations and the ranking component of the model are jointly estimated. We show that this approach results in a substantial boost in performance on the event ordering task with respect to the previous approaches, both on natural and crowdsourced texts. © 2014 Association for Computational Linguistics.},
publisher={Association for Computational Linguistics (ACL)},
isbn={9781941643020},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{NoAuthor2014vii,
title={Preface},
journal={Semantic Structures: Advances in Natural Language Processing},
year={2014},
volume={23},
pages={vii-xxii},
doi={10.4324/9781315857367},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925832844&doi=10.4324%2f9781315857367&partnerID=40&md5=7ab70ae47ddd07e864783ed5692a96f0},
publisher={Taylor and Francis},
isbn={9781315857367},
language={English},
document_type={Editorial},
source={Scopus},
}

@CONFERENCE{Al-Moadhen20141023,
author={Al-Moadhen, A. and Packianather, M. and Setchi, R. and Qiu, R.},
title={Automation in handling uncertainty in semantic-knowledge based robotic task-planning by using markov logic networks},
journal={Procedia Computer Science},
year={2014},
volume={35},
number={C},
pages={1023-1032},
doi={10.1016/j.procs.2014.08.188},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924198504&doi=10.1016%2fj.procs.2014.08.188&partnerID=40&md5=49ee4adbb8217f44a15d6b7e53410048},
abstract={Generating plans in real world environments by mobile robot planner is a challenging task due to the uncertainty and environment dynamics. Therefore, task-planning should take in its consideration these issues when generating plans. Semantic knowledge domain has been proposed as a source of information for deriving implicit information and generating semantic plans. This paper extends the Semantic-Knowledge Based (SKB) plan generation to take into account the uncertainty in existing of objects, with their types and properties, and proposes a new approach to construct plans based on probabilistic values which are derived from Markov Logic Networks (MLN). An MLN module is established for probabilistic learning and inferencing together with semantic information to provide a basis for plausible learning and reasoning services in supporting of robot task-planning. In addition, an algorithm has been devised to construct MLN from semantic knowledge. By providing a means of modeling uncertainty in system architecture, task-planning serves as a supporting tool for robotic applications that can benefit from probabilistic inference within a semantic domain. This approach is illustrated using test scenarios run in a domestic environment using a mobile robot. © 2014 The Authors. Published by Elsevier B.V.},
author_keywords={Markov logic networks;  Planning under uncertainty;  Semantic-knowledge based;  Task-planning},
publisher={Elsevier B.V.},
issn={18770509},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Nissan2014780,
author={Nissan, E. and Hacohen-Kerner, Y.},
title={GALLURA and the challenge of combining phono-semantic matching with story-generation: Zoonomastic illustration},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2014},
volume={LNCS 8003},
pages={780-866},
doi={10.1007/978-3-642-45327-4_19},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921452007&doi=10.1007%2f978-3-642-45327-4_19&partnerID=40&md5=50912231b176b9971fd8e1d0b367a299},
abstract={In the present paper, we illustrate on animal names (zoonyms) the specification and design of the phono-semantic matching (PSM) module which within the architecture of GALLURA, should be upstream in the control flow. The PSM module takes a word (e.g., a zoonym, or then a place-name) and an indication of a target-language (in practice, Hebrew). The desired output of the PSM module should be a set of alternative segmentations or sets of such native (i.e., Hebrew) words or roots that are derivationally "relevant" (in a folk-etymological sense). That output of the PSM module should then be an input for the story-telling module of GALLURA. The desired output of GALLURA is a combination of folk-etymology and storytelling, a humorous aetiological (i.e., explanatory) tale. A story is sought, that by bridging through some narrative trajectory the input and output of the PSM module, would back up the folk-etymology proposed by the output of the PSM module. Phono-semantic matching (PSM), itself not an easy task, is only part of the skills required. Here however we focus on the processing in the designed PSM module. © Springer-Verlag Berlin Heidelberg 2014.},
author_keywords={Aetiological tales;  Aggadic Midrash;  Artificial intelligence;  Dasyuridae (quolls and dunnarts);  Explanation;  Folk-etymology;  GALLURA;  Hebrew;  Hedgehog (Erinaceidae);  Humour;  Lexicon;  Liber animalium;  Morphological analysis;  Multiagent systems;  Phono-semantic matching (PSM);  PSM module of GALLURA;  Squirrel (Sciurus);  Story-generation;  Terminology;  Verbal creativity;  Wordplay;  Wordplay;  Zoonyms (animal names)},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={03029743},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Pappu2014120,
author={Pappu, A. and Rudnicky, A.I.},
title={Learning situated knowledge bases through dialog},
journal={Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
year={2014},
pages={120-124},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910052631&partnerID=40&md5=0a97008981d025b4d5adae49c30e04a2},
abstract={To respond to a user's query, dialog agents can use a knowledge base that is either domain specific, commonsense (e.g., NELL, Freebase) or a combination of both. The drawback is that domain-specific knowledge bases will likely be limited and static; commonsense ones are dynamic but contain general information found on the web and will be sparse with respect to a domain. We address this issue through a system that solicits situational information from its users in a domain that provides information on events (seminar talks) to augment its knowledge base (covering an academic field). We find that this knowledge is consistent and useful and that it provides reliable information to users. We show that, in comparison to a base system, users find that retrievals are more relevant when the system uses its informally acquired knowledge to augment their queries. Copyright © 2014 ISCA.},
author_keywords={Human knowledge;  Knowledge base;  Situated domain;  Spoken dialog},
publisher={International Speech and Communication Association},
issn={2308457X},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Frermann201449,
author={Frermann, L. and Titov, I. and Pinkal, M.},
title={A hierarchical Bayesian model for unsupervised induction of script knowledge},
journal={14th Conference of the European Chapter of the Association for Computational Linguistics 2014, EACL 2014},
year={2014},
pages={49-57},
doi={10.3115/v1/e14-1006},
note={cited By 38},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905708550&doi=10.3115%2fv1%2fe14-1006&partnerID=40&md5=d30e67d7ecde60324fe2d2b9e8f61577},
abstract={Scripts representing common sense knowledge about stereotyped sequences of events have been shown to be a valuable resource for NLP applications. We present a hierarchical Bayesian model for unsupervised learning of script knowledge from crowdsourced descriptions of human activities. Events and constraints on event ordering are induced jointly in one unified framework. We use a statistical model over permutations which captures event ordering constraints in a more flexible way than previous approaches. In order to alleviate the sparsity problem caused by using relatively small datasets, we incorporate in our hierarchical model an informed prior on word distributions. The resulting model substantially outperforms a state-of-the-Art method on the event ordering task. © 2014 Association for Computational Linguistics.},
publisher={Association for Computational Linguistics (ACL)},
isbn={9781632663962},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Steinbauer201463,
author={Steinbauer, G. and Mühlbacher, C.},
title={Using common sense invariants in belief management for autonomous agents},
journal={AAAI Spring Symposium - Technical Report},
year={2014},
volume={SS-14-05},
pages={63-70},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904889270&partnerID=40&md5=5bde4aceeb64ec2e6bca0055f3f59ad1},
abstract={For an agent or robot it is essential to detect inconsistencies between its internal belief and the real world. To detect these inconsistencies we reuse background knowledge from a common sense knowledge base as invariants. This enables us to detect and diagnose inconsistencies which can be missed if no background knowledge is used. In order to be able to reuse common sense from other sources a mapping between the knowledge representation in the robot system and the common sense knowledge bases is introduced. In this paper we specify the properties which have to be respected in order to achieve a proper mapping. Moreover, we show a preliminary implementation of such a mapping for the Cyc knowledge base and evaluate this implementation in a simple delivery robot domain. Copyright © 2014, Association for the Advancement of Artificial Intelligence. All rights reserved.},
publisher={AI Access Foundation},
isbn={9781577356455},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Santofimia2014,
author={Santofimia, M.J. and Martinez-Del-Rincon, J. and Nebel, J.-C.},
title={Episodic reasoning for vision-based human action recognition},
journal={Scientific World Journal},
year={2014},
volume={2014},
doi={10.1155/2014/270171},
art_number={270171},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901748747&doi=10.1155%2f2014%2f270171&partnerID=40&md5=81c8c50e97011994456f65b89eeb3ebc},
abstract={Smart Spaces, Ambient Intelligence, and Ambient Assisted Living are environmental paradigms that strongly depend on their capability to recognize human actions. While most solutions rest on sensor value interpretations and video analysis applications, few have realized the importance of incorporating common-sense capabilities to support the recognition process. Unfortunately, human action recognition cannot be successfully accomplished by only analyzing body postures. On the contrary, this task should be supported by profound knowledge of human agency nature and its tight connection to the reasons and motivations that explain it. The combination of this knowledge and the knowledge about how the world works is essential for recognizing and understanding human actions without committing common-senseless mistakes. This work demonstrates the impact that episodic reasoning has in improving the accuracy of a computer vision system for human action recognition. This work also presents formalization, implementation, and evaluation details of the knowledge model that supports the episodic reasoning. © 2014 Maria J. Santofimia et al.},
publisher={The Scientific World Journal},
issn={23566140},
language={English},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tsvetkov2014551,
author={Tsvetkov, V.Y.},
title={Information field},
journal={Life Science Journal},
year={2014},
volume={11},
number={5},
pages={551-554},
art_number={83},
note={cited By 15},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901364232&partnerID=40&md5=2e618157f530383f37c676197ecb1b7d},
abstract={The theme of the present article concerns the information field. It is stated here that information field may be discrete or continuous. Information field includes two types: natural information field and artificial information field. Information field is the basis of data organization. Information field is the basis of information models building and information modeling. In this article it is described that information field as well as information models have common elements, which are information units. It is stated that information field possesses a plenty of varieties.},
author_keywords={Artificial information field;  Information;  Information field;  Information models;  Information units;  Knowledge;  Natural information field},
publisher={Zhengzhou University},
issn={10978135},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Skulkittiyut201363,
author={Skulkittiyut, W. and Lee, H. and Ngo Lam, T. and Tran Minh, Q. and Baharudin, M.A. and Fujioka, T. and Kamioka, E. and Mizukawa, M.},
title={Commonsense knowledge extraction for tidy-up robotic service in domestic environments},
journal={Proceedings of IEEE Workshop on Advanced Robotics and its Social Impacts, ARSO},
year={2013},
pages={63-69},
doi={10.1109/ARSO.2013.6705507},
art_number={6705507},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894115369&doi=10.1109%2fARSO.2013.6705507&partnerID=40&md5=7e125dfaf03cda61006fd1eaf8fc44d8},
abstract={Commonsense is one of the keys to enable human-robot communication in daily life scenarios. It is very difficult for a robot to do tasks ordered by a human without having some basic knowledge to understand the human's commands. This paper proposes a method to automatically build commonsense knowledge for the "Tidy-up" service, in which a robot is asked to take objects such as books, cups, dishes on a table to appropriate places automatically. We defined three object classes that are necessary for the service, namely "Washable"-objects that need to be washed, "Reusable"- objects that need to be stored for reuse, and "Trashable"-objects that need to be disposed of. For each object, multiple attributes were extracted from both the ConceptNet knowledge base and the Google search engine, and fed to classifiers to classify the object into the appropriate class. To evaluate the proposed method, output from classifiers were compared with the result from actual human. The result showed that the proposed approach is efficient in classifying objects and in providing object type as commonsense knowledge, hence, helping the robots to understand human intention and to provide intuitive service. © 2013 IEEE.},
issn={21627568},
isbn={9781479923694},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Zang2013689,
author={Zang, L.-J. and Cao, C. and Cao, Y.-N. and Wu, Y.-M. and Cao, C.-G.},
title={A survey of commonsense knowledge acquisition},
journal={Journal of Computer Science and Technology},
year={2013},
volume={28},
number={4},
pages={689-719},
doi={10.1007/s11390-013-1369-6},
note={cited By 18},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880048451&doi=10.1007%2fs11390-013-1369-6&partnerID=40&md5=11d280096713be9fc946cf777b405ca7},
abstract={Collecting massive commonsense knowledge (CSK) for commonsense reasoning has been a long time standing challenge within artificial intelligence research. Numerous methods and systems for acquiring CSK have been developed to overcome the knowledge acquisition bottleneck. Although some specific commonsense reasoning tasks have been presented to allow researchers to measure and compare the performance of their CSK systems, we compare them at a higher level from the following aspects: CSK acquisition task (what CSK is acquired from where), technique used (how can CSK be acquired), and CSK evaluation methods (how to evaluate the acquired CSK). In this survey, we first present a categorization of CSK acquisition systems and the great challenges in the field. Then, we review and compare the CSK acquisition systems in detail. Finally, we conclude the current progress in this field and explore some promising future research issues. © 2013 Springer Science+Business Media New York & Science Press, China.},
author_keywords={commonsense knowledge;  knowledge acquisition;  knowledge representation and reasoning},
issn={10009000},
coden={JCTEE},
language={English},
document_type={Article},
source={Scopus},
}

@ARTICLE{Perconti201395,
author={Perconti, P.},
title={Two kinds of common sense knowledge (and a constraint for machine consciousness design)},
journal={International Journal of Machine Consciousness},
year={2013},
volume={5},
number={1},
pages={95-101},
doi={10.1142/S1793843013400076},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877779255&doi=10.1142%2fS1793843013400076&partnerID=40&md5=e66de3a24b14f53327e20f53ed9b2ce5},
abstract={In this paper, it will be argued that common sense knowledge has not a unitary structure. It is rather articulated at two different levels: a deep and a superficial level of common sense. The deep level is based on know-how procedures, on metaphorical frames built on imaginative bodily representations, and on a set of adaptive behaviors. Superficial level includes beliefs and judgments. They can be true or false and are culture dependent. Deep common sense is unavailable for any fast change, because it depends more on human biology than on cultural conventions. The deep level of common sense is characterized by a sensorimotor representational format, while the superficial level is largely made by propositional entities. This difference can be considered as a constraint for machine consciousness design, insofar this latter should be based on a reliable model of common sense knowledge. © 2013 World Scientific Publishing Company.},
author_keywords={Common sense knowledge;  computational correlates of folk knowledge;  machine consciousness},
issn={17938430},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Montazeri2013,
author={Montazeri, N. and Hobbs, J.R. and Hovy, E.},
title={How text mining can help lexical and commonsense knowledgebase construction},
journal={COMMONSENSE 2013 - 11th International Symposium on Logical Formalizations of Commonsense Reasoning},
year={2013},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986889390&partnerID=40&md5=ec6eddec3d95df3946322e1d7afe93b8},
abstract={In an enterprise called "deep lexical semantics", we developvarious core theories of fundamental commonsensephenomena and define English word senses by means ofaxioms using predicates explicated in these theories. Thisenables deep inferences that require commonsenseknowledge about how the world functions. There aredifficulties in our approach to manually axiomatize wordsand commonsense knowledge. First, developing axioms isdone by experts and this means the process is slow andexpensive. Second, it is hard, if possible at all, to predict inadvance all the kinds of axioms that should be encoded incore theories. In this paper we present a method forharvesting from free-form text on the web, simple axiomsfor change-of-state verbs which is a combination of textmining and manual filtering. Focusing on two change-ofstate verbs, break and cut, we show how the harvestedaxioms can help in addressing the above problems. © COMMONSENSE 2013 - 11th International Symposium on Logical Formalizations of Commonsense Reasoning. All rights reserved.},
publisher={Association for the Advancement of Artificial Intelligence},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Gil2013285,
author={Gil, Y.},
title={Social knowledge collection},
journal={Handbook of Human Computation},
year={2013},
pages={285-296},
doi={10.1007/978-1-4614-8806-4_24},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963617976&doi=10.1007%2f978-1-4614-8806-4_24&partnerID=40&md5=335abbee2ff30d252163e0d8e3316725},
publisher={Springer New York},
isbn={9781461488064; 9781461488057},
language={English},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Ohlsson2013,
author={Ohlsson, S. and Sloan, R.H. and Turán, G. and Urasky, A.},
title={Verbal IQ of a four-year old achieved by an AI system},
journal={COMMONSENSE 2013 - 11th International Symposium on Logical Formalizations of Commonsense Reasoning},
year={2013},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944072463&partnerID=40&md5=2d63a84f8a020896fe00f337c8421b1b},
abstract={One view of common-sense reasoning ability is that it is theability to perform those tasks with verbal inputs and outputsthat have traditionally been difficult for computer systems,but are easy for fairly young children. We administered theverbal part of the Wechsler Preschool and Primary Scale ofIntelligence (WPPSI-III, Third Edition) to the ConceptNet 4system.The IQ test's questions (e.g., "Why do we shake hands?" or"What do apples and bananas have in common") weretranslated into ConceptNet 4 inputs using a combination ofthe simple natural language processing tools that come withConceptNet together with short Python programs that wewrote. The question-answering primarily used the part ofthe ConceptNet system that represents the knowledge as amatrix based on spectral methods (AnalogySpace).We found that the system has a Verbal IQ that is average fora four-year-old child, but below average for 5, 6, and 7 yearolds. Large variations from subtest to subtest indicatepotential areas of improvement. In particular, results werestrongest for the Vocabulary and Similarities subtests,intermediate for the Information subtest, and lowest for theComprehension and Word Reasoning subtests.Comprehension is the subtest most strongly associated withcommon sense.Children's verbal IQ tests offer a new, objective, third-partymetric for the evaluation and comparison of common-senseAI systems. © COMMONSENSE 2013 - 11th International Symposium on Logical Formalizations of Commonsense Reasoning. All rights reserved.},
publisher={Association for the Advancement of Artificial Intelligence},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Shylaja2013383,
author={Shylaja, K.R. and Vijayakumar, M.V. and Davis, D.N. and Prasad, E.V.},
title={Cognitive architecture to evolve conscious cognitive tasks into common sense actions on agents},
journal={Lecture Notes in Engineering and Computer Science},
year={2013},
volume={1},
pages={383-388},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903471632&partnerID=40&md5=68952cecdb83a7f7b7c8d6d3d8e2223f},
abstract={The research work describes the design of a cognitive model to demonstrate consciousness and common sense concepts on the robots to make them more situated and smart in executing their tasks assigned using cognitive approach. The work also explains how the robots convert their learned knowledge into common sense knowledge over a period of time. COCOCA (Consciousness and Common sense Cognitive Architecture) uses Global Workspace Theory (Baars, 1988) and Multi Draft Model (Dennett, 1991) for consciousness, EM-One architecture (Singh, 2005) for common sense critics and SMCA (Society of Mind Cognitive Architecture) for agent architecture (Vijaykumar, 2008), as metaphors. The control system designed enables a machine to build a knowledge base through conscious explicit learning of task operations. This agent after using this knowledge repeatedly on a scenario converts this into task specific common sense knowledge. The research is aiming to prove that common sense tasks are executed faster and utilize less resource than conscious tasks. The performance of agents improves if it can execute most of its routine tasks as common sense. The COCO cognitive architecture proposed in this paper is a five layered architecture with layers such as; reflexive layer, reactive layer, deliberative layer, consciousness layer and common sense layer, where the agents of each layer exhibit different level of consciousness and intelligence.},
author_keywords={Access and Phenomenal Consciousness;  Cognition;  Cognitive architecture;  Common sense critics;  Consciousness},
publisher={Newswood Limited},
issn={20780958},
isbn={9789881925169},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ohlsson201389,
author={Ohlsson, S. and Sloan, R.H. and Turán, G. and Urasky, A.},
title={Verbal IQ of a four-year old achieved by an AI system},
journal={AAAI Workshop - Technical Report},
year={2013},
volume={WS-13-17},
pages={89-91},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898896914&partnerID=40&md5=efed2012a07d0db553a95bac0e1d4520},
abstract={Verbal tasks that have traditionally been difficult for computer systems but are easy for young children are among AI's "grand challenges". We present the results of testing the ConceptNet 4 system on the verbal part of the standard WPPSI-III IQ test, using simple test-answering algorithms. It is found that the system has the Verbal IQ of an average four-year-old child. Copyright © 2013, Association for the Advancement of Artificial.},
publisher={AI Access Foundation},
isbn={9781577356288},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Chen20133422,
author={Chen, C.-H. and Li, A.-F. and Lee, Y.-C.},
title={A fuzzy coherent rule mining algorithm},
journal={Applied Soft Computing Journal},
year={2013},
volume={13},
number={7},
pages={3422-3428},
doi={10.1016/j.asoc.2012.12.031},
note={cited By 22},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893704472&doi=10.1016%2fj.asoc.2012.12.031&partnerID=40&md5=eb148858897c22bcfceba0fd0350db0b},
abstract={In real-world applications, transactions usually consist of quantitative values. Many fuzzy data mining approaches have thus been proposed for finding fuzzy association rules with the predefined minimum support from the give quantitative transactions. However, the common problems of those approaches are that an appropriate minimum support is hard to set, and the derived rules usually expose common-sense knowledge which may not be interesting in business point of view. In this paper, an algorithm for mining fuzzy coherent rules is proposed for overcoming those problems with the properties of propositional logic. It first transforms quantitative transactions into fuzzy sets. Then, those generated fuzzy sets are collected to generate candidate fuzzy coherent rules. Finally, contingency tables are calculated and used for checking those candidate fuzzy coherent rules satisfy the four criteria or not. If yes, it is a fuzzy coherent rule. Experiments on the foodmart dataset are also made to show the effectiveness of the proposed algorithm. © 2013 Elsevier B.V. All rights reserved.},
author_keywords={Data mining;  Fuzzy association rules;  Fuzzy coherent rules;  Fuzzy set;  Membership function},
publisher={Elsevier Ltd},
issn={15684946},
language={English},
document_type={Article},
source={Scopus},
}

@ARTICLE{Rzepka2013318,
author={Rzepka, R. and Muramoto, K. and Araki, K.},
title={Limiting context by using the web to minimize conceptual jump size},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2013},
volume={7070 LNAI},
pages={318-326},
doi={10.1007/978-3-642-44958-1_25},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893187146&doi=10.1007%2f978-3-642-44958-1_25&partnerID=40&md5=1f7ede51529ad4123f97825540ffbaa6},
abstract={In this paper we introduce our ideas on how experiences from real situations could be processed to decrease what Solomonoff called "Conceptual Jump Size". We introduce applications based on commonsense knowledge showing that vast corpora are able to automatically confirm the validity of the output, and also replace a "trainer", which could lead to decreasing human influence and speeding up the process of finding solutions not provided by such a "trainer" or by real world descriptions. Following this idea, we also suggest a shift toward combining natural languages with programming languages to smoothen transitions between layers of Solomonoff's "Concept net" leading from primitive concepts to a problem solution. © 2013 Springer-Verlag Berlin Heidelberg.},
author_keywords={artificial trainers;  Conceptual Jump Size;  Natural Language Processing;  Wisdom of (Web) Crowd},
publisher={Springer Verlag},
issn={03029743},
isbn={9783642449574},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Kalashankar201345,
author={Kalashankar, B.A. and Prasad, N.N.S.S.R.K.},
title={Transdisciplinary way of knowledge representation in intelligent autonomous systems with neural networks},
journal={Advances in Intelligent Systems and Computing},
year={2013},
volume={208 AISC},
pages={45-54},
doi={10.1007/978-3-642-37374-9_5},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876261389&doi=10.1007%2f978-3-642-37374-9_5&partnerID=40&md5=0ecd954fd3be69e37612230f077d3474},
abstract={Learning is the highly complex and ongoing process in each and every stage of life to enrich our thought processes, in the same way our thought process is involved in the course of acquiring auxiliary knowledge with an existing knowledge. In this perspective human stands ahead on every stage of life, an important difference between intelligent autonomous applications and human intelligence is our ability to exploit common sense knowledge attained from a lifetime of learning and experiences to inform our decision-making and behavior. This allows humans to adapt easily to novel situations where intelligent autonomous systems fail in some cases due to lack of situation-specific rules and generalization capabilities. In the ongoing research and development, most of the intelligent autonomous systems can do the task as expected, but still fails in the process of acquiring additional knowledge apart from the acquired knowledge. This is due to our way of learning methodologies, domain experience, and way of thought processes where we involved as a disciplinary, multidisciplinary, interdisciplinary and transdisciplinary approach of learning. In order for intelligent autonomous systems to exploit common sense knowledge in reasoning as humans do, understand domain specific basics, then, we need to provide them with human-like reasoning strategies. In complex situation, in particular, representation of multiple domain knowledge to resolve the problem based on the situation. The domain knowledge should be adapted at multidimensional way or parallel or dynamic way of adapting the knowledge. This leads intelligent autonomous systems to use an alternative when it fails at the particular point of solving the problem, so for better result knowledge should be organized in the better way. Knowledge is dominantly organized in disciplines, as multidisciplinary and interdisciplinary research is developing at the boundaries of the scientific disciplines [8]. In this paper we compare transdisciplinary, interdisciplinary, multidisciplinary and non-disciplinary forms of knowledge representations and adopt transdisciplinary approach for intelligent autonomous systems with neural networks. © 2013 Springer-Verlag.},
author_keywords={AI;  Expert System;  Intelligent Autonomous Systems;  Interdisciplinary;  Knowledge Representation;  Multidisciplinary;  Transdisciplinary and Artificial Neural Networks},
publisher={Springer Verlag},
issn={21945357},
isbn={9783642373732},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Perconti2013249,
author={Perconti, P.},
title={A biologically-inspired perspective on commonsense knowledge},
journal={Advances in Intelligent Systems and Computing},
year={2013},
volume={196 AISC},
pages={249-250},
doi={10.1007/978-3-642-34274-5_44},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870802160&doi=10.1007%2f978-3-642-34274-5_44&partnerID=40&md5=ded5be860b21bee20345abc72a28e85f},
abstract={Since the seminal papers by John McCarthy [1,2], the problem to design intelligent systems able to handle common sense knowledge has become a real puzzle [3,6,7]. According to the McCarthy and Hayes suggestion, "The first task [to construct a general intelligent computer program] is to define even a naive, common-sense view of the world precisely enough to program a computer to act accordingly. This is a very difficult task in itself" [5]: 6. Perhaps the frame problem, i.e., how can a representational system deal with the enormous amount of knowledge that is necessary to everyday behaviour, needs nowadays a new account. The BICA challenge, that is, the challenge to make a general purpose and computational equivalent of the human intelligence by means of an approach based on biologically inspired cognitive architectures, can be considered as an example of this kind of new perspective [1,8]. © 2013 Springer-Verlag.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783642342738},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Gebser20121,
author={Gebser, M. and Kaminski, R. and Kaufmann, B. and Schaub, T.},
title={Answer set solving in practice},
journal={Synthesis Lectures on Artificial Intelligence and Machine Learning},
year={2012},
volume={19},
pages={1-240},
doi={10.2200/S00457ED1V01Y201211AIM019},
note={cited By 204},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872075045&doi=10.2200%2fS00457ED1V01Y201211AIM019&partnerID=40&md5=f2d80feb978d811a6ac6657accc11cb2},
abstract={Answer Set Programming (ASP) is a declarative problem solving approach, initially tailored to modeling problems in the area of Knowledge Representation and Reasoning (KRR). More recently, its attractive combination of a rich yet simple modeling language with high-performance solving capacities has sparked interest in many other areas even beyond KRR. This book presents a practical introduction to ASP, aiming at using ASP languages and systems for solving application problems. Starting from the essential formal foundations, it introduces ASP's solving technology, modeling language and methodology, while illustrating the overall solving process by practical examples. Copyright © 2012 by Morgan & Claypool.},
author_keywords={answer set programming;  declarative problem solving;  logic programming},
issn={19394608},
isbn={9781608459711},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Kuo201218,
author={Kuo, Y.-L. and Hsu, J.Y.-J. and Shih, F.},
title={Contextual commonsense knowledge acquisition from social content by crowd-sourcing explanations},
journal={AAAI Workshop - Technical Report},
year={2012},
volume={WS-12-08},
pages={18-24},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875720859&partnerID=40&md5=05105d1bc2de8ca62f90264b488bd1f9},
abstract={Contextual knowledge is essential in answering questions given specific observations. While recent approaches to building commonsense knowledge bases via text mining and/or crowdsourcing are successful, contextual knowledge is largely missing. To address this gap, this paper presents SocialExplain, a novel approach to acquiring contextual commonsense knowledge from explanations of social content. The acquisition process is broken into two cognitively simple tasks: to identify contextual clues from the given social content, and to explain the content with the clues. An experiment was conducted to show that multiple pieces of contextual commonsense knowledge can be identified from a small number of tweets. Online users verified that 92.45% of the acquired sentences are good, and 95.92% are new sentences compared with existing crowd-sourced commonsense knowledge bases. Copyright © 2012, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
isbn={9781577355731},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhou20123962,
author={Zhou, K. and Zillich, M. and Zender, H. and Vincze, M.},
title={Web mining driven object locality knowledge acquisition for efficient robot behavior},
journal={IEEE International Conference on Intelligent Robots and Systems},
year={2012},
pages={3962-3969},
doi={10.1109/IROS.2012.6385931},
art_number={6385931},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872342339&doi=10.1109%2fIROS.2012.6385931&partnerID=40&md5=112523afbeedf6959a42143ab18b2d3a},
abstract={As an important information resource, visual perception has been widely employed for various indoor mobile robots. The common-sense knowledge about object locality (CSOL), e.g. a cup is usually located on the table top rather than on the floor and vice versa for a trash bin, is a very helpful context information for a robotic visual search task. In this paper, we propose an online knowledge acquisition mechanism for discovering CSOL, thereby facilitating a more efficient and robust robotic visual search. The proposed mechanism is able to create conceptual knowledge with the information acquired from the largest and the most diverse medium - the Internet. Experiments using an indoor mobile robot demonstrate the efficiency of our approach as well as reliability of goal-directed robot behaviour. © 2012 IEEE.},
issn={21530858},
isbn={9781467317375},
coden={85RBA},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Varadarajan20121343,
author={Varadarajan, K.M. and Vincze, M.},
title={AfRob: The affordance network ontology for robots},
journal={IEEE International Conference on Intelligent Robots and Systems},
year={2012},
pages={1343-1350},
doi={10.1109/IROS.2012.6386232},
art_number={6386232},
note={cited By 33},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872293601&doi=10.1109%2fIROS.2012.6386232&partnerID=40&md5=3fc71cbf703d2d27517bd8475904b8e9},
abstract={AfNet, The Affordance Network is an open affordance computing initiative that provides affordance knowledge ontologies for common household articles in terms of affordance features using surface forms termed as afbits (affordance bits). AfNet currently offers 68 base affordance features (25 structural, 10 material, 33 grasp), providing over 200 object category definitions in terms of 4000 afbits. Symbol grounding algorithms for these affordance features enable recognition of objects in visual (RGB-D) data. While AfNet is built as a generic visual knowledge ontology for recognition, it is well suited for deployment on domestic robots. In this paper, we describe AfRob, an extension of AfNet for robotic applications. AfRob builds upon AfNet by imbibing semantic context and mapping for holistic recognition and manipulation of objects in domestic environments. AfRob also offers modules to enable robots to interact and grasp objects through the generation of grasp affordances. The paper also details the inference mechanisms that adapt AfNet for robots in domestic contexts. Results demonstrate the efficiency of the affordance driven approach to holistic visual processing. © 2012 IEEE.},
issn={21530858},
isbn={9781467317375},
coden={85RBA},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lam2012546,
author={Lam, T.N. and Mayama, K. and Mizukawa, M. and Lee, H.},
title={Extraction of commonsense knowledge for "bring something" robotic service at home},
journal={2012 IEEE International Conference on Mechatronics and Automation, ICMA 2012},
year={2012},
pages={546-551},
doi={10.1109/ICMA.2012.6283166},
art_number={6283166},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867602266&doi=10.1109%2fICMA.2012.6283166&partnerID=40&md5=45ec87a626c676b2b474bd0457c53e7b},
abstract={Sharing commonsense knowledge is one key to realize symbiosis between human and robot. However, as human knowledge is so complicated, it is difficult to extract appropriate information for robot. This paper presents our approach to extract the core part from Basic-level Knowledge Network (BKN) to be used for intuitive "Bring something" robotic service. A two-step filtering method was implemented based on the weighting mechanism of BKN. The first step used one weighting parameter to filter the most irrelevant data. The second step combined all weighting parameters from BKN with user response data from a questionnaire to estimate commoness of object-activity connections. Result showed that the proposed approach is efficient to extract the most common activities related to each object in BKN, therefore to help robot understands human intention and provide intuitive service. © 2012 IEEE.},
author_keywords={commonsense knowledge;  robotic service},
isbn={9781467312776},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Periñán-Pascual2012184,
author={Periñán-Pascual, C.},
title={The situated common-sense knowledge in FunGramKB},
journal={Review of Cognitive Linguistics},
year={2012},
volume={10},
number={1},
pages={184-214},
doi={10.1075/rcl.10.1.06per},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867491881&doi=10.1075%2frcl.10.1.06per&partnerID=40&md5=2048a71a62da1512a261c0a9a0a163ef},
abstract={It has been widely demonstrated that expectation-based schemata, along the lines of Lakoff's propositional Idealized Cognitive Models, play a crucial role in text comprehension. Discourse inferences are grounded on the shared generalized knowledge which is activated from the situational model underlying the text surface dimension. From a cognitive-plausible and linguistic-aware approach to knowledge representation, FunGramKB stands out for being a dynamic repository of lexical, constructional and conceptual knowledge which contributes to simulate human-level reasoning. The objective of this paper is to present a script model as a carrier of the situated common-sense knowledge required to help knowledge engineers construct more "intelligent" natural language processing systems. © John Benjamins Publishing Company.},
author_keywords={Common-sense knowledge;  FunGramKB;  Natural language understanding;  Script;  Situated knowledge},
issn={18779751},
language={English},
document_type={Review},
source={Scopus},
}

@ARTICLE{Daoutis2012213,
author={Daoutis, M. and Coradeschi, S. and Loutfi, A.},
title={Towards concept anchoring for cognitive robots},
journal={Intelligent Service Robotics},
year={2012},
volume={5},
number={4},
pages={213-228},
doi={10.1007/s11370-012-0117-z},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867580722&doi=10.1007%2fs11370-012-0117-z&partnerID=40&md5=db737ce324bc75b3c394e03c1ee262ca},
abstract={We present a model for anchoring categorical conceptual information which originates from physical perception and the web. The model is an extension of the anchoring framework which is used to create and maintain over time semantically grounded sensor information. Using the augmented anchoring framework that employs complex symbolic knowledge from a commonsense knowledge base, we attempt to ground and integrate symbolic and perceptual data that are available on the web. We introduce conceptual anchors which are representations of general, concrete conceptual terms. We show in an example scenario how conceptual anchors can be coherently integrated with perceptual anchors and commonsense information for the acquisition of novel concepts. © 2012 Springer-Verlag.},
author_keywords={Anchoring;  Categorical perception;  Commonsense information;  Knowledge representation;  Near sets},
publisher={Springer Verlag},
issn={18612776},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Björkelund20127,
author={Björkelund, A. and Malec, J. and Nilsson, K. and Nugues, P. and Bruyninckx, H.},
title={Knowledge for intelligent industrial robots},
journal={AAAI Spring Symposium - Technical Report},
year={2012},
volume={SS-12-02},
pages={7-12},
note={cited By 31},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864886860&partnerID=40&md5=c047f8fc4e7c3b5d36a3997fecba3ad4},
abstract={This paper describes an attempt to provide more intelligence to industrial robotics and automation systems. We develop an architecture to integrate disparate knowledge representations used in different places in robotics and automation. This knowledge integration framework, a possibly distributed entity, abstracts the components used in design or production as data sources, and provides a uniform access to them via standard interfaces. Representation is based on the ontology formalizing the process, product and resource triangle, where skills are considered the common element of the three. Production knowledge is being collected now and a preliminary version of KIF undergoes verification. Copyright © 2012, Association for the Advancement of Artificial Intelligence. All rights reserved.},
isbn={9781577355519},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Reich2012251,
author={Reich, Y. and Shai, O.},
title={The interdisciplinary engineering knowledge genome},
journal={Research in Engineering Design},
year={2012},
volume={23},
number={3},
pages={251-264},
doi={10.1007/s00163-012-0129-x},
note={cited By 30},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865601993&doi=10.1007%2fs00163-012-0129-x&partnerID=40&md5=f4ae9dea76ad4b68810c56cd1ddd7a7c},
abstract={Parallel to the concept of the human genome and its impact on biology and other disciplines, we revealed a similar concept in engineering sciences, termed the "Interdisciplinary Engineering Knowledge Genome", which is an organized collection of system and method "genes" that encode instructions for generating new systems and methods in diverse engineering disciplines. Resting on the firm mathematical foundation of combinatorial representations, the Interdisciplinary Engineering Knowledge Genome unifies many engineering disciplines, providing a basis for transforming knowledge between them, supporting new educational practices, promoting inventions, aiding design, and bootstrapping new discoveries in engineering and science. Given the formal underlying combinatorial representations, these merits could be automated. This paper elucidates this new concept and demonstrates its value and power in engineering design. © Springer-Verlag London Limited 2012.},
author_keywords={Biomimicry;  Human genome;  Knowledge management;  Knowledge representation},
issn={09349839},
coden={REEDE},
language={English},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Speer20123679,
author={Speer, R. and Havasi, C.},
title={Representing general relational knowledge in concept net 5},
journal={Proceedings of the 8th International Conference on Language Resources and Evaluation, LREC 2012},
year={2012},
pages={3679-3686},
note={cited By 294},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021734728&partnerID=40&md5=a641a016295b544a18a29f881e08578c},
abstract={ConceptNet is a knowledge representation project, providing a large semantic graph that describes general human knowledge and how it is expressed in natural language. This paper presents the latest iteration, ConceptNet 5, including its fundamental design decisions, ways to use it, and evaluations of its coverage and accuracy.},
author_keywords={Common sense;  ConceptNet;  Semantic networks},
publisher={European Language Resources Association (ELRA)},
isbn={9782951740877},
language={English},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lam20123679,
author={Lam, T.N. and Lee, H. and Mayama, K. and Mizukawa, M.},
title={Evaluation of commonsense knowledge for intuitive robotic service},
journal={Proceedings - IEEE International Conference on Robotics and Automation},
year={2012},
pages={3679-3684},
doi={10.1109/ICRA.2012.6225332},
art_number={6225332},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864435946&doi=10.1109%2fICRA.2012.6225332&partnerID=40&md5=4a7e0cf6450db0bf8200d577330a2229},
abstract={Human commonsense is required to improve quality of robotic application. However, to acquire the necessary knowledge, robot needs to evaluate the appropriateness of the data it has collected. This paper presents an evaluation method, by combining the weighting mechanism in commonsense databases with a set of weighting factors. The method was verified on our Basic-level Knowledge Network. We conducted questionnaire to collect a commonsense data set and estimate weighting factors. Result showed that, the proposed method was able to build Robot Technology (RT) Ontology for a smart "Bring something" robotic service. More importantly, it allowed robot to learn new knowledge when necessary. An intuitive human-robot interface application was developed as an example base on our approach. © 2012 IEEE.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={10504729},
isbn={9781467314039},
coden={PIIAE},
language={English},
document_type={Conference Paper},
source={Scopus},
}