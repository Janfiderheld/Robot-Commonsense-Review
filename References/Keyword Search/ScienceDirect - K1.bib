@article{SCHLENOFF20151,
title = {Preface: Special issue on knowledge driven robotics and manufacturing},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {33},
pages = {1-2},
year = {2015},
note = {Special Issue on Knowledge Driven Robotics and Manufacturing},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2014.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0736584514000763},
author = {Craig Schlenoff and Stephen Balakirsky and Edson Prestes}
}
@article{IKEDA202116,
title = {Knowledge Based Accuracy Improvement in Programming by Demonstration of Point Based Processes},
journal = {Procedia Manufacturing},
volume = {55},
pages = {16-23},
year = {2021},
note = {FAIM 2021},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2021.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S2351978921002018},
author = {Markus Ikeda and Naresh Chitturi and Markus Ganglbauer and Andreas Pichler},
keywords = {knowledge based robotics, virtual reality, mixed reality, programming by demonstration, human robot interaction},
abstract = {Productivity and flexibility are antagonists with opposite goals. Until now, optimal productivity could only be achieved in fully automated inflexible serial production. Increased demand for flexibility due to individualized products e.g. in most SMEs requires an increased level of flexibility – also for robots that should provide improved skills as well as improved means of interaction to simplify programming. Instrumented tools based on 3D tracking technology can be used as interfaces in Programming by Demonstration (PbD) scenarios but are prone to inaccuracies introduced by human demonstration. This paper presents a programming paradigm that combines a semantic model based geometric reasoning paradigms with an instrumented tool based PbD approach in order to compensate those introduced inaccuracies as well as investigates basic accuracies of demonstration of point based operations.}
}
@article{HILIA2013540,
title = {Trends and Challenges in Formal Specification and Verification of Services Composition in Ambient Assisted Living Applications},
journal = {Procedia Computer Science},
volume = {19},
pages = {540-547},
year = {2013},
note = {The 4th International Conference on Ambient Systems, Networks and Technologies (ANT 2013), the 3rd International Conference on Sustainable Energy Information Technology (SEIT-2013)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.06.072},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913006807},
author = {Mohamed Hilia and Abdelghani Chibani and Karim Djouani},
keywords = {Ambient Assisted Living, Ontology Specification and Modeling, Theorem Proving, Isabelle/HOL},
abstract = {Emerging Ambient Assisted Living (AAL) applications, as a part of AmI applications, deal essentially with health- care related applications such as assistance to the elderly and handicapped persons, emergency services. Several ap- proaches and techniques have been proposed, providing formal languages modeled with ontologies (e.g. OWL-S, WSMO) that describe in semantic way the environment. In this paper, relevant challenges of the current AAL ap- plication development, with a focus on the formal specification and verification are discussed. A formal system which enable to specify a semantic model represented by an upper ontology is presented. The innovative aspect of the proposed model concerns the use of a constructive description logic.}
}
@article{CVITANIC202251,
title = {Improved state estimation of a robot end-effector using laser tracker and inertial sensor fusion},
journal = {CIRP Journal of Manufacturing Science and Technology},
volume = {38},
pages = {51-61},
year = {2022},
issn = {1755-5817},
doi = {https://doi.org/10.1016/j.cirpj.2022.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S1755581722000608},
author = {Toni Cvitanic and Shreyes Melkote and Stephen Balakirsky},
keywords = {State estimation, Laser tracker, Industrial manipulator, Inertial measurement unit, Real-time},
abstract = {An increased focus on automation in the aerospace industry has led to a demand for flexible manipulators that can achieve high trajectory following accuracy for tasks like machining, joining, and painting. These tasks require an accurate, real-time state estimation of the robot’s end-effector. Currently, the most accurate methods of estimating the end-effector state involve using high-end position and orientation sensors such as laser trackers and camera-based metrology systems and tend to focus on accurately estimating the end-effector position and orientation. This paper investigates the potential benefits and practical considerations in supplementing the data from these kinds of sensors with acceleration and angular velocity measurements obtained from an inertial measurement unit (IMU) to improve the overall robot end-effector state estimation including its velocity and angular acceleration. The sensor fusion is achieved using a Kalman Filter for motions with no rotation and using a Particle Filter for motions with rotation. Simulation results indicate that up to 95% improvement in velocity estimation accuracy, and up to 45% improvement in angular acceleration estimation accuracy can be achieved by fusing IMU data with laser tracker data. In addition, the paper analyzes the thresholds of sensor accuracy beyond which fusion no longer provides significant benefits. Finally, hardware experiments are conducted using a fusion of robot encoder data with IMU measurements. These experiments indicate up to 40% improvement in velocity estimation accuracy from the sensor fusion.}
}
@article{BALAKIRSKY20131205,
title = {Knowledge driven robotics for kitting applications},
journal = {Robotics and Autonomous Systems},
volume = {61},
number = {11},
pages = {1205-1214},
year = {2013},
note = {Ubiquitous Robotics},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2013.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0921889013000602},
author = {Stephen Balakirsky and Zeid Kootbally and Thomas Kramer and Anthony Pietromartire and Craig Schlenoff and Satyandra Gupta},
keywords = {Ontology, Robotics, Manufacturing, Knowledge representation},
abstract = {This article presents a newly developed knowledge methodology/model that was designed to support the IEEE Robotics and Automation Society’s Ontologies for Robotics and Automation Working Group. This methodology/model allows for the creation of systems that demonstrate flexibility, agility, and the ability to be rapidly re-tasked. The methodology/model will be illustrated through a case study in the area of robotic kit building. Through this case study, the knowledge model will be presented, and automatic tools for optimizing the knowledge representation for planning systems and execution systems will be discussed.}
}
@article{2014iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {35},
pages = {iii-ix},
year = {2014},
note = {Knowledge-Based and Intelligent Information & Engineering Systems 18th Annual Conference, KES-2014 Gdynia, Poland, September 2014 Proceedings},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(14)01235-6},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914012356}
}
@article{TIPARY2021102140,
title = {Generic development methodology for flexible robotic pick-and-place workcells based on Digital Twin},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {71},
pages = {102140},
year = {2021},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2021.102140},
url = {https://www.sciencedirect.com/science/article/pii/S0736584521000259},
author = {Bence Tipary and Gábor Erdős},
keywords = {Digital twin, Modeling, Flexibility, Robot, Calibration, Planning},
abstract = {Together with the trends of mass personalization, flexible robotic applications become more and more popular. Although conventional robotic automation of workpiece manipulation seems to be solved, advanced tasks still need great amount of effort to be reached. In most cases, on-site robot programming methods, which are intuitive and easy to use, are not applicable in flexible scenarios. On the other hand, the application of offline programming methods requires careful modeling and planning. Consequently, this paper proposes a generalized development methodology for flexible robotic pick-and-place workcells, in order to provide guidance and thus facilitate the development process. The methodology is based on the Digital Twin (DT) concept, which allows the iterative refinement of the workcell both in the digital and in the physical space. The goal is to speed up the overall commissioning (or reconfiguration) process and reduce the amount of work in the physical workcell. This can be achieved by digitizing and automating the development, and maintaining sufficient twin closeness. With that, the operation of the digital model can be accurately realized in the physical workcell. The methodology is presented through a semi-structured pick-and-place task, realized in an experimental robotic workcell together with a reconfiguration scenario.}
}
@article{KOSTAVELIS2016173,
title = {Robot navigation via spatial and temporal coherent semantic maps},
journal = {Engineering Applications of Artificial Intelligence},
volume = {48},
pages = {173-187},
year = {2016},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2015.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0952197615002596},
author = {Ioannis Kostavelis and Konstantinos Charalampous and Antonios Gasteratos and John K. Tsotsos},
keywords = {Semantic mapping, Robot navigation, Augmented navigation graph, Place recognition, Time proximity},
abstract = {The ability of mobile robots to sense, interpret and map their environments in human terms is decisive for their applicability to everyday activities hereafter. Bearing this view in mind, we present here, for the first time, an integrated framework that aims: (i) to introduce a semantic mapping method and (ii) to use this semantic map, as a means to provide a hierarchical navigation solution. The semantic map is formed in a bottom-up fashion, along the robot׳s course, relying on the conceptual space quantization, the time proximity and the spatial coherence integrated into the labeled sparse topological map. A novel time-evolving augmented navigation graph determines the semantic topology of the explored environment and the connectivity among the recognized places expressed by the inter-place transition probability. The robot navigation part is addressed through an interface that facilitates human robot interaction. High level orders are passed to the robots and unfolded recursively, in a top-down fashion, into local navigation data. The performance of the proposed framework was evaluated on long range real world data and exhibited remarkable results.}
}
@article{ALMOADHEN20141023,
title = {Automation in Handling Uncertainty in Semantic-knowledge based Robotic Task-planning by Using Markov Logic Networks},
journal = {Procedia Computer Science},
volume = {35},
pages = {1023-1032},
year = {2014},
note = {Knowledge-Based and Intelligent Information & Engineering Systems 18th Annual Conference, KES-2014 Gdynia, Poland, September 2014 Proceedings},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.08.188},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914011533},
author = {Ahmed Al-Moadhen and Michael Packianather and Rossi Setchi and Renxi Qiu},
keywords = {Task-Planning, Semantic-Knowledge Based, Planning Under Uncertainty, Markov Logic Networks},
abstract = {Generating plans in real world environments by mobile robot planner is a challenging task due to the uncertainty and environment dynamics. Therefore, task-planning should take in its consideration these issues when generating plans. Semantic knowledge domain has been proposed as a source of information for deriving implicit information and generating semantic plans. This paper extends the Semantic-Knowledge Based (SKB) plan generation to take into account the uncertainty in existing of objects, with their types and properties, and proposes a new approach to construct plans based on probabilistic values which are derived from Markov Logic Networks (MLN). An MLN module is established for probabilistic learning and inferencing together with semantic information to provide a basis for plausible learning and reasoning services in supporting of robot task-planning. In addition, an algorithm has been devised to construct MLN from semantic knowledge. By providing a means of modeling uncertainty in system architecture, task-planning serves as a supporting tool for robotic applications that can benefit from probabilistic inference within a semantic domain. This approach is illustrated using test scenarios run in a domestic environment using a mobile robot.}
}
@article{GARCIA20143042,
title = {Knowledge Base Representation for Humanoid Robot Skills},
journal = {IFAC Proceedings Volumes},
volume = {47},
number = {3},
pages = {3042-3047},
year = {2014},
note = {19th IFAC World Congress},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20140824-6-ZA-1003.02229},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016420744},
author = {Daniel Hernández García and Concepción A. Monje and Carlos Balaguer},
abstract = {The ultimate goal for humanoid robotics research is to develop humanoid robotic systems capable and flexible enough to handle the challenge of working alongside human in complex natural environments performing everyday tasks. To reach this goal it is key to develop appropriate structures in which to organize the acquire knowledge in a manner that allows the system to retrieve it in order to use it to fulfil its missions. In this work a knowledge base representation of the robot skills knowledge organized in terms of the relationships between objects, actions and event frames is proposed.}
}
@article{DING2019105,
title = {Robotic Task Oriented Knowledge Graph for Human-Robot Collaboration in Disassembly},
journal = {Procedia CIRP},
volume = {83},
pages = {105-110},
year = {2019},
note = {11th CIRP Conference on Industrial Product-Service Systems},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2019.03.121},
url = {https://www.sciencedirect.com/science/article/pii/S2212827119304263},
author = {Yiwen Ding and Wenjun Xu and Zhihao Liu and Zude Zhou and Duc Truong Pham},
keywords = {human-robot collaboration, product disassembly, knowledge graph, knowledge base},
abstract = {Traditional disassembly methods, such as manual and robotic disassembly, are no longer competent for the requirement of the complexity of the disassembly product. Therefore, the human-robot collaboration concept can be introduced to realize a novel disassembly system, towards increasing the flexibility and adaptability of them. In order to facilitate the efficient and smooth human-robot collaboration in disassembly, it is necessary to make the disassembly system more intelligent. In this paper, a robotic knowledge graph is proposed to provide an assistant for those who lack the relevant knowledge to complete the disassembly task. By natural language processing method, this paper extracts entities and relationships from the disassembly data to build a knowledge base in the form of knowledge graph. Combining graph-based knowledge representation, a prototype system is developed for human to acquire, analyze and manage the disassembly knowledge. Finally, a case study demonstrates that the proposed robotic knowledge graph has savings in terms of disassembly time, idle time and human workload, and it can be applied to assist human operator in disassembly by providing human and robots with various kinds of the needed knowledge.}
}
@article{20141,
title = {Contents},
journal = {Procedia Computer Science},
volume = {35},
pages = {1-10},
year = {2014},
note = {Knowledge-Based and Intelligent Information & Engineering Systems 18th Annual Conference, KES-2014 Gdynia, Poland, September 2014 Proceedings},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.08.079},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914010448}
}
@article{IKEDA202132,
title = {Geometric Reasoning enabled One Shot Learning for Robotic Tasks},
journal = {Procedia Manufacturing},
volume = {55},
pages = {32-39},
year = {2021},
note = {FAIM 2021},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2021.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S2351978921002031},
author = {Markus Ikeda and Markus Ganglbauer and Naresh Chitturi and Andreas Pichler},
keywords = {human robot knowledge transfer, one shot learning, programming by demonstration, cognitive robotics},
abstract = {Flexible robotics will be a major enabling technology for the application of robot-based automation in other than traditionally suitable automotive or electronics production with high volumes. Increased demand for flexibility due to individualized production typical for most SMEs require an increased level of flexibility – also for robots that should be able to learn as well as provide an increased level of autonomy due to improved skills and extended reasoning capabilities. This publication tries to find out if novel ANN methodology that is able to process 3D surface data is applicable to generalize process knowledge in a one shot learning by demonstration situation in order to be able to execute tasks on similar but geometrically unequal objects in future settings. The methodology generalizes not on symbolic or trajectory level but on surface geometry level and was applied to a simple geometric object on lab scale. The algorithms introduced are applicable to more complex objects with practical relevance.}
}
@article{TENORTH2017151,
title = {Representations for robot knowledge in the KnowRob framework},
journal = {Artificial Intelligence},
volume = {247},
pages = {151-169},
year = {2017},
note = {Special Issue on AI and Robotics},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2015.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0004370215000843},
author = {Moritz Tenorth and Michael Beetz},
keywords = {Knowledge representation, Autonomous robots, Knowledge-enabled robotics},
abstract = {In order to robustly perform tasks based on abstract instructions, robots need sophisticated knowledge processing methods. These methods have to supply the difference between the (often shallow and symbolic) information in the instructions and the (detailed, grounded and often real-valued) information needed for execution. For filling these information gaps, a robot first has to identify them in the instructions, reason about suitable information sources, and combine pieces of information from different sources and of different structure into a coherent knowledge base. To this end we propose the KnowRob knowledge processing system for robots. In this article, we discuss why the requirements of a robot knowledge processing system differ from what is commonly investigated in AI research, and propose to re-consider a KR system as a semantically annotated view on information and algorithms that are often already available as part of the robot's control system. We then introduce representational structures and a common vocabulary for representing knowledge about robot actions, events, objects, environments, and the robot's hardware as well as inference procedures that operate on this common representation. The KnowRob system has been released as open-source software and is being used on several robots performing complex object manipulation tasks. We evaluate it through prototypical queries that demonstrate the expressive power and its impact on the robot's performance.}
}